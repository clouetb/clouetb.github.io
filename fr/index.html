<!DOCTYPE html>
<html prefix="        og: http://ogp.me/ns# article: http://ogp.me/ns/article#     " vocab="http://ogp.me/ns" lang="fr">
<head>
<meta charset="utf-8">
<meta name="description" content="Bits of IT, boardgames, and rants.">
<meta name="viewport" content="width=device-width">
<title>Benoît's blog</title>
<link href="../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS (fr)" hreflang="fr" href="rss.xml">
<link rel="alternate" type="application/rss+xml" title="RSS (en)" hreflang="en" href="../rss.xml">
<link rel="canonical" href="https://blog.bclouet.eu/fr/">
<!--[if lt IE 9]><script src="../assets/js/html5shiv-printshiv.min.js"></script><![endif]--><script async defer data-website-id="2d0b3614-5a9e-47aa-98ab-b24073d8b1f1" src="https://analytics.bclouet.eu/script.js"></script>
</head>
<body>
    <a href="#content" class="sr-only sr-only-focusable">Aller au contenu principal</a>
    <div id="container">
        
    <header id="header"><h1 id="brand"><a href="." title="Benoît's blog" rel="home">

        <span id="blog-title">Benoît's blog</span>
    </a></h1>

        
        <div id="toptranslations">
            <h2>Langues :</h2>
            
    <ul class="translations">
<li><a href="../" rel="alternate" hreflang="en">English</a></li>
    </ul>
</div>

        
    <nav id="menu"><ul>
<li><a href="archive.html">Archives</a></li>
                <li><a href="categories/">Étiquettes</a></li>
                <li><a href="rss.xml">Flux RSS</a></li>

    

    
    
    </ul></nav></header><main id="content"><div class="postindex">
    <article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/" class="u-url">Running llama3 on the GPU of a RK1 Turing Pi</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Benoît Clouet
            </span></p>
            <p class="dateline">
            <a href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/" rel="bookmark">
            <time class="published dt-published" datetime="2025-03-08T15:19:42+01:00" itemprop="datePublished" title="2025-03-08 15:19">2025-03-08 15:19</time></a>
            </p>
                <p class="commentline">
    
    <a href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#disqus_thread" data-disqus-identifier="cache/posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi.html">Commentaires</a>


        </p>
</div>
    </header><div class="e-content entry-content">
    <p>When I left my job in IT Operations, my colleagues were very generous and allowed me to fund the purchase of a Rockchip 3588 SBC Arm board (<a class="reference external" href="https://docs.turingpi.com/docs/turing-pi2-intro">https://docs.turingpi.com/docs/turing-pi2-intro</a>) for my experiments. Many thanks to them, you know who you are.</p>
<img alt="/images/RK1.webp" src="../images/RK1.webp"><p>As this was a kickstarter, it took a while for the beast to reach me. Add to that the time it took to make it fully operational, which meant not only building a decent system image, but also delving into the specifications of the machine (which gave me a chance to brush up on memory addressing concepts I’d forgotten for at least twenty years) and building a fully functional compilation chain. But that’s another story, back to the main topic of this first article.</p>
<p>When Llama3 was released, which wasn’t that long ago, I saw quite a few people getting worked up on the support forums for these famous RK1 cards and wondering whether it was even possible to run this new model (some others a bit older) on their precious ones. The answer is yes, I did it, but there are still some rough edges. Here is a recipe for reaching this goal, which should also work for most of the mali-enabled Arm boards as long as you have enough memory on it. 8GB of system memory seems to be a minimum for running inference on a 4 bits quantized model (see below for more info). This is also possible because the system memory is equally accessible by the GPU and the CPU. The weights themselves are weighting a whooping 75GB so grab yourself a nice SD Card!</p>
<p>However, a word of warning here, keep in mind that quantization may require more memory than the 8 GB required at inference time. In the instruction presented below, the weights quantization operation is using nearly 20 GB of memory. I don’t know if such process can be performed with less memory. Two options may be used for getting through this issue :</p>
<ul class="simple">
<li><p>Use a good amount of swap, which could help finishing the process at the expense of a much longer quantization time;</p></li>
<li><p>Perform quantization on another machine with a sufficient amount of memory. Indeed, weights seem to be portable across machine architectures. Theoretically, it should be feasible to run the quantization step on another machine and then transfer the result of this operation on the target machine. This should save you from having to build a cross compilation toolchain. I haven’t tested this though.</p></li>
</ul>
<p>Now, the interesting part is that you can run some conversation with Llama 3 using mlc-llm for offloading the inference on the mali G610 GPU. Using this technique, it should be theoretically possible to run Llama3 on an 8GB Orange PI 5 which has the same processor. It needs a bit of tinkering though but it should work.</p>
<p>Here are the steps.</p>
<section id="installation-of-the-opencl-drivers"><h2>Installation of the OpenCL drivers</h2>
<p>Install the mali-g610-firmware package for getting in place the firmware blobs containing the openCL stubs. For this, follow the excellent instructions given here <a class="reference external" href="https://clehaxze.tw/gemlog/2023/06-17-setting-up-opencl-on-rk3588-using-libmali.gmi">https://clehaxze.tw/gemlog/2023/06-17-setting-up-opencl-on-rk3588-using-libmali.gmi</a> by Martin Chang. After completing the installation, add yourself in the render group to gain access to the DRI devices:</p>
<div class="code"><pre class="code shell"><a id="rest_code_8bfea2cc80414daea9ae77a3b37940f5-1" name="rest_code_8bfea2cc80414daea9ae77a3b37940f5-1" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_8bfea2cc80414daea9ae77a3b37940f5-1"></a>$<span class="w"> </span>sudo<span class="w"> </span>usermod<span class="w"> </span>-a<span class="w"> </span>-G<span class="w"> </span>render<span class="w"> </span>&lt;your<span class="w"> </span>username&gt;
</pre></div>
<p>Then check everything is detected correctly:</p>
<div class="code"><pre class="code shell"><a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-1" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-1" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-1"></a>$<span class="w"> </span>sudo<span class="w"> </span>clinfo
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-2" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-2" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-2"></a>Number<span class="w"> </span>of<span class="w"> </span>platforms<span class="w">                               </span><span class="m">3</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-3" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-3" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-3"></a><span class="w">  </span>Platform<span class="w"> </span>Name<span class="w">                                   </span>ARM<span class="w"> </span>Platform
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-4" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-4" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-4"></a><span class="w">  </span>Platform<span class="w"> </span>Vendor<span class="w">                                 </span>ARM
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-5" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-5" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-5"></a><span class="w">  </span>Platform<span class="w"> </span>Version<span class="w">                                </span>OpenCL<span class="w"> </span><span class="m">2</span>.1<span class="w"> </span>v1.g6p0-01eac0.2819f9d4dbe0b5a2f89c835d8484f9cd
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-6" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-6" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-6"></a><span class="w">  </span>Platform<span class="w"> </span>Profile<span class="w">                                </span>FULL_PROFILE
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-7" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-7" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-7"></a><span class="w">  </span>Platform<span class="w"> </span>Extensions<span class="w">                             </span>cl_khr_global_int32_base_atomics<span class="w"> </span>cl_khr_global_int32_extended_atomics<span class="w"> </span>cl_khr_local_int32_base_atomics<span class="w"> </span>cl_khr_local_int32_extended_atomics<span class="w"> </span>cl_khr_byte_addressable_store<span class="w"> </span>cl_khr_3d_image_writes<span class="w"> </span>cl_khr_int64_base_atomics<span class="w"> </span>cl_khr_int64_extended_atomics<span class="w"> </span>cl_khr_fp16<span class="w"> </span>cl_khr_icd<span class="w"> </span>cl_khr_egl_image<span class="w"> </span>cl_khr_image2d_from_buffer<span class="w"> </span>cl_khr_depth_images<span class="w"> </span>cl_khr_subgroups<span class="w"> </span>cl_khr_subgroup_extended_types<span class="w"> </span>cl_khr_subgroup_non_uniform_vote<span class="w"> </span>cl_khr_subgroup_ballot<span class="w"> </span>cl_khr_il_program<span class="w"> </span>cl_khr_priority_hints<span class="w"> </span>cl_khr_create_command_queue<span class="w"> </span>cl_khr_spirv_no_integer_wrap_decoration<span class="w"> </span>cl_khr_extended_versioning<span class="w"> </span>cl_khr_device_uuid<span class="w"> </span>cl_arm_core_id<span class="w"> </span>cl_arm_printf<span class="w"> </span>cl_arm_non_uniform_work_group_size<span class="w"> </span>cl_arm_import_memory<span class="w"> </span>cl_arm_import_memory_dma_buf<span class="w"> </span>cl_arm_import_memory_host<span class="w"> </span>cl_arm_integer_dot_product_int8<span class="w"> </span>cl_arm_integer_dot_product_accumulate_int8<span class="w"> </span>cl_arm_integer_dot_product_accumulate_saturate_int8<span class="w"> </span>cl_arm_scheduling_controls<span class="w"> </span>cl_arm_controlled_kernel_termination<span class="w"> </span>cl_ext_cxx_for_opencl
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-8" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-8" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-8"></a><span class="w">  </span>Platform<span class="w"> </span>Extensions<span class="w"> </span><span class="k">function</span><span class="w"> </span>suffix<span class="w">             </span>ARM
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-9" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-9" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-9"></a><span class="w">  </span>Platform<span class="w"> </span>Host<span class="w"> </span>timer<span class="w"> </span>resolution<span class="w">                  </span>1ns
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-10" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-10" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-10"></a>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-11" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-11" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-11"></a><span class="w">  </span>Platform<span class="w"> </span>Name<span class="w">                                   </span>Clover
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-12" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-12" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-12"></a><span class="w">  </span>Platform<span class="w"> </span>Vendor<span class="w">                                 </span>Mesa
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-13" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-13" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-13"></a><span class="w">  </span>Platform<span class="w"> </span>Version<span class="w">                                </span>OpenCL<span class="w"> </span><span class="m">1</span>.1<span class="w"> </span>Mesa<span class="w"> </span><span class="m">22</span>.3.6
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-14" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-14" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-14"></a><span class="w">  </span>Platform<span class="w"> </span>Profile<span class="w">                                </span>FULL_PROFILE
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-15" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-15" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-15"></a><span class="w">  </span>Platform<span class="w"> </span>Extensions<span class="w">                             </span>cl_khr_icd
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-16" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-16" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-16"></a><span class="w">  </span>Platform<span class="w"> </span>Extensions<span class="w"> </span><span class="k">function</span><span class="w"> </span>suffix<span class="w">             </span>MESA
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-17" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-17" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-17"></a>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-18" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-18" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-18"></a><span class="w">  </span>Platform<span class="w"> </span>Name<span class="w">                                   </span>rusticl
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-19" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-19" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-19"></a><span class="w">  </span>Platform<span class="w"> </span>Vendor<span class="w">                                 </span>Mesa/X.org
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-20" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-20" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-20"></a><span class="w">  </span>Platform<span class="w"> </span>Version<span class="w">                                </span>OpenCL<span class="w"> </span><span class="m">3</span>.0
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-21" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-21" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-21"></a><span class="w">  </span>Platform<span class="w"> </span>Profile<span class="w">                                </span>FULL_PROFILE
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-22" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-22" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-22"></a><span class="w">  </span>Platform<span class="w"> </span>Extensions<span class="w">                             </span>cl_khr_icd
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-23" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-23" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-23"></a><span class="w">  </span>Platform<span class="w"> </span>Extensions<span class="w"> </span>with<span class="w"> </span>Version<span class="w">                </span>cl_khr_icd<span class="w">                                                       </span>0x400000<span class="w"> </span><span class="o">(</span><span class="m">1</span>.0.0<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-24" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-24" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-24"></a><span class="w">  </span>Platform<span class="w"> </span>Numeric<span class="w"> </span>Version<span class="w">                        </span>0xc00000<span class="w"> </span><span class="o">(</span><span class="m">3</span>.0.0<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-25" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-25" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-25"></a><span class="w">  </span>Platform<span class="w"> </span>Extensions<span class="w"> </span><span class="k">function</span><span class="w"> </span>suffix<span class="w">             </span>MESA
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-26" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-26" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-26"></a><span class="w">  </span>Platform<span class="w"> </span>Host<span class="w"> </span>timer<span class="w"> </span>resolution<span class="w">                  </span>0ns
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-27" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-27" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-27"></a>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-28" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-28" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-28"></a><span class="w">  </span>Platform<span class="w"> </span>Name<span class="w">                                   </span>ARM<span class="w"> </span>Platform
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-29" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-29" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-29"></a>Number<span class="w"> </span>of<span class="w"> </span>devices<span class="w">                                 </span><span class="m">1</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-30" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-30" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-30"></a>arm_release_ver<span class="w"> </span>of<span class="w"> </span>this<span class="w"> </span>libmali<span class="w"> </span>is<span class="w"> </span><span class="s1">'g6p0-01eac0'</span>,<span class="w"> </span>rk_so_ver<span class="w"> </span>is<span class="w"> </span><span class="s1">'7'</span>.
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-31" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-31" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-31"></a><span class="w">  </span>Device<span class="w"> </span>Name<span class="w">                                     </span>Mali-LODX<span class="w"> </span>r0p0
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-32" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-32" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-32"></a><span class="w">  </span>Device<span class="w"> </span>Vendor<span class="w">                                   </span>ARM
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-33" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-33" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-33"></a><span class="w">  </span>Device<span class="w"> </span>Vendor<span class="w"> </span>ID<span class="w">                                </span>0xa8670000
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-34" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-34" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-34"></a><span class="w">  </span>Device<span class="w"> </span>Version<span class="w">                                  </span>OpenCL<span class="w"> </span><span class="m">2</span>.1<span class="w"> </span>v1.g6p0-01eac0.2819f9d4dbe0b5a2f89c835d8484f9cd
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-35" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-35" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-35"></a><span class="w">  </span>Device<span class="w"> </span>UUID<span class="w">                                     </span>000067a8-0100-0000-0000-000000000000
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-36" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-36" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-36"></a><span class="w">  </span>Driver<span class="w"> </span>UUID<span class="w">                                     </span>1e0cb80a-4d25-a21f-2c18-f7de010f1315
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-37" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-37" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-37"></a><span class="w">  </span>Valid<span class="w"> </span>Device<span class="w"> </span>LUID<span class="w">                               </span>No
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-38" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-38" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-38"></a><span class="w">  </span>Device<span class="w"> </span>LUID<span class="w">                                     </span><span class="m">0000</span>-000000000000
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-39" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-39" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-39"></a><span class="w">  </span>Device<span class="w"> </span>Node<span class="w"> </span>Mask<span class="w">                                </span><span class="m">0</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-40" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-40" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-40"></a><span class="w">  </span>Device<span class="w"> </span>Numeric<span class="w"> </span>Version<span class="w">                          </span>0x801000<span class="w"> </span><span class="o">(</span><span class="m">2</span>.1.0<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-41" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-41" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-41"></a><span class="w">  </span>Driver<span class="w"> </span>Version<span class="w">                                  </span><span class="m">2</span>.1
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-42" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-42" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-42"></a><span class="w">  </span>Device<span class="w"> </span>OpenCL<span class="w"> </span>C<span class="w"> </span>Version<span class="w">                         </span>OpenCL<span class="w"> </span>C<span class="w"> </span><span class="m">2</span>.0<span class="w"> </span>v1.g6p0-01eac0.2819f9d4dbe0b5a2f89c835d8484f9cd
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-43" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-43" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-43"></a><span class="w">  </span>Device<span class="w"> </span>OpenCL<span class="w"> </span>C<span class="w"> </span>Numeric<span class="w"> </span>Version<span class="w">                 </span>0x800000<span class="w"> </span><span class="o">(</span><span class="m">2</span>.0.0<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-44" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-44" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-44"></a><span class="w">  </span>Device<span class="w"> </span>C++<span class="w"> </span><span class="k">for</span><span class="w"> </span>OpenCL<span class="w"> </span>Numeric<span class="w"> </span>Version<span class="w">           </span>0x400000<span class="w"> </span><span class="o">(</span><span class="m">1</span>.0.0<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-45" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-45" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-45"></a><span class="w">  </span>Device<span class="w"> </span>Type<span class="w">                                     </span>GPU
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-46" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-46" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-46"></a><span class="w">  </span>Device<span class="w"> </span>Profile<span class="w">                                  </span>FULL_PROFILE
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-47" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-47" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-47"></a><span class="w">  </span>Device<span class="w"> </span>Available<span class="w">                                </span>Yes
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-48" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-48" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-48"></a><span class="w">  </span>Compiler<span class="w"> </span>Available<span class="w">                              </span>Yes
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-49" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-49" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-49"></a><span class="w">  </span>Linker<span class="w"> </span>Available<span class="w">                                </span>Yes
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-50" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-50" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-50"></a><span class="w">  </span>Max<span class="w"> </span>compute<span class="w"> </span>units<span class="w">                               </span><span class="m">4</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-51" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-51" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-51"></a><span class="w">  </span>Available<span class="w"> </span>core<span class="w"> </span>IDs<span class="w"> </span><span class="o">(</span>ARM<span class="o">)</span><span class="w">                        </span><span class="m">0</span>,<span class="w"> </span><span class="m">2</span>,<span class="w"> </span><span class="m">16</span>,<span class="w"> </span><span class="m">18</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-52" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-52" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-52"></a><span class="w">  </span>Max<span class="w"> </span>clock<span class="w"> </span>frequency<span class="w">                             </span>1000MHz
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-53" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-53" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-53"></a><span class="w">  </span>Device<span class="w"> </span>Partition<span class="w">                                </span><span class="o">(</span>core<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-54" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-54" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-54"></a><span class="w">    </span>Max<span class="w"> </span>number<span class="w"> </span>of<span class="w"> </span>sub-devices<span class="w">                     </span><span class="m">0</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-55" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-55" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-55"></a><span class="w">    </span>Supported<span class="w"> </span>partition<span class="w"> </span>types<span class="w">                     </span>None
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-56" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-56" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-56"></a><span class="w">    </span>Supported<span class="w"> </span>affinity<span class="w"> </span>domains<span class="w">                    </span><span class="o">(</span>n/a<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-57" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-57" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-57"></a><span class="w">  </span>Max<span class="w"> </span>work<span class="w"> </span>item<span class="w"> </span>dimensions<span class="w">                        </span><span class="m">3</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-58" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-58" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-58"></a><span class="w">  </span>Max<span class="w"> </span>work<span class="w"> </span>item<span class="w"> </span>sizes<span class="w">                             </span>1024x1024x1024
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-59" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-59" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-59"></a><span class="w">  </span>Max<span class="w"> </span>work<span class="w"> </span>group<span class="w"> </span>size<span class="w">                             </span><span class="m">1024</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-60" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-60" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-60"></a><span class="w">  </span>Preferred<span class="w"> </span>work<span class="w"> </span>group<span class="w"> </span>size<span class="w"> </span>multiple<span class="w"> </span><span class="o">(</span>kernel<span class="o">)</span><span class="w">     </span><span class="m">16</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-61" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-61" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-61"></a><span class="w">  </span>Max<span class="w"> </span>sub-groups<span class="w"> </span>per<span class="w"> </span>work<span class="w"> </span>group<span class="w">                   </span><span class="m">64</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-62" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-62" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-62"></a><span class="w">  </span>Preferred<span class="w"> </span>/<span class="w"> </span>native<span class="w"> </span>vector<span class="w"> </span>sizes
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-63" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-63" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-63"></a><span class="w">    </span>char<span class="w">                                                </span><span class="m">16</span><span class="w"> </span>/<span class="w"> </span><span class="m">4</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-64" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-64" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-64"></a><span class="w">    </span>short<span class="w">                                                </span><span class="m">8</span><span class="w"> </span>/<span class="w"> </span><span class="m">2</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-65" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-65" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-65"></a><span class="w">    </span>int<span class="w">                                                  </span><span class="m">4</span><span class="w"> </span>/<span class="w"> </span><span class="m">1</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-66" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-66" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-66"></a><span class="w">    </span>long<span class="w">                                                 </span><span class="m">2</span><span class="w"> </span>/<span class="w"> </span><span class="m">1</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-67" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-67" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-67"></a><span class="w">    </span>half<span class="w">                                                 </span><span class="m">8</span><span class="w"> </span>/<span class="w"> </span><span class="m">2</span><span class="w">        </span><span class="o">(</span>cl_khr_fp16<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-68" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-68" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-68"></a><span class="w">    </span>float<span class="w">                                                </span><span class="m">4</span><span class="w"> </span>/<span class="w"> </span><span class="m">1</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-69" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-69" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-69"></a><span class="w">    </span>double<span class="w">                                               </span><span class="m">0</span><span class="w"> </span>/<span class="w"> </span><span class="m">0</span><span class="w">        </span><span class="o">(</span>n/a<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-70" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-70" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-70"></a><span class="w">  </span>Half-precision<span class="w"> </span>Floating-point<span class="w"> </span>support<span class="w">           </span><span class="o">(</span>cl_khr_fp16<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-71" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-71" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-71"></a><span class="w">    </span>Denormals<span class="w">                                     </span>Yes
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-72" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-72" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-72"></a><span class="w">    </span>Infinity<span class="w"> </span>and<span class="w"> </span>NANs<span class="w">                             </span>Yes
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-73" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-73" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-73"></a><span class="w">    </span>Round<span class="w"> </span>to<span class="w"> </span>nearest<span class="w">                              </span>Yes
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-74" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-74" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-74"></a><span class="w">    </span>Round<span class="w"> </span>to<span class="w"> </span>zero<span class="w">                                 </span>Yes
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-75" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-75" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-75"></a><span class="w">    </span>Round<span class="w"> </span>to<span class="w"> </span>infinity<span class="w">                             </span>Yes
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-76" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-76" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-76"></a><span class="w">    </span>IEEE754-2008<span class="w"> </span>fused<span class="w"> </span>multiply-add<span class="w">               </span>Yes
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-77" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-77" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-77"></a><span class="w">    </span>Support<span class="w"> </span>is<span class="w"> </span>emulated<span class="w"> </span><span class="k">in</span><span class="w"> </span>software<span class="w">               </span>No
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-78" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-78" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-78"></a><span class="w">  </span>Single-precision<span class="w"> </span>Floating-point<span class="w"> </span>support<span class="w">         </span><span class="o">(</span>core<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-79" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-79" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-79"></a><span class="w">    </span>Denormals<span class="w">                                     </span>Yes
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-80" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-80" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-80"></a><span class="w">    </span>Infinity<span class="w"> </span>and<span class="w"> </span>NANs<span class="w">                             </span>Yes
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-81" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-81" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-81"></a><span class="w">    </span>Round<span class="w"> </span>to<span class="w"> </span>nearest<span class="w">                              </span>Yes
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-82" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-82" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-82"></a><span class="w">    </span>Round<span class="w"> </span>to<span class="w"> </span>zero<span class="w">                                 </span>Yes
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-83" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-83" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-83"></a><span class="w">    </span>Round<span class="w"> </span>to<span class="w"> </span>infinity<span class="w">                             </span>Yes
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-84" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-84" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-84"></a><span class="w">    </span>IEEE754-2008<span class="w"> </span>fused<span class="w"> </span>multiply-add<span class="w">               </span>Yes
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-85" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-85" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-85"></a><span class="w">    </span>Support<span class="w"> </span>is<span class="w"> </span>emulated<span class="w"> </span><span class="k">in</span><span class="w"> </span>software<span class="w">               </span>No
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-86" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-86" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-86"></a><span class="w">    </span>Correctly-rounded<span class="w"> </span>divide<span class="w"> </span>and<span class="w"> </span>sqrt<span class="w"> </span>operations<span class="w">  </span>No
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-87" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-87" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-87"></a><span class="w">  </span>Double-precision<span class="w"> </span>Floating-point<span class="w"> </span>support<span class="w">         </span><span class="o">(</span>n/a<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-88" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-88" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-88"></a><span class="w">  </span>Address<span class="w"> </span>bits<span class="w">                                    </span><span class="m">64</span>,<span class="w"> </span>Little-Endian
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-89" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-89" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-89"></a><span class="w">  </span>Global<span class="w"> </span>memory<span class="w"> </span>size<span class="w">                              </span><span class="m">33327280128</span><span class="w"> </span><span class="o">(</span><span class="m">31</span>.04GiB<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-90" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-90" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-90"></a><span class="w">  </span>Error<span class="w"> </span>Correction<span class="w"> </span>support<span class="w">                        </span>No
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-91" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-91" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-91"></a><span class="w">  </span>Max<span class="w"> </span>memory<span class="w"> </span>allocation<span class="w">                           </span><span class="m">33327280128</span><span class="w"> </span><span class="o">(</span><span class="m">31</span>.04GiB<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-92" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-92" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-92"></a><span class="w">  </span>Unified<span class="w"> </span>memory<span class="w"> </span><span class="k">for</span><span class="w"> </span>Host<span class="w"> </span>and<span class="w"> </span>Device<span class="w">              </span>Yes
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-93" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-93" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-93"></a><span class="w">  </span>Shared<span class="w"> </span>Virtual<span class="w"> </span>Memory<span class="w"> </span><span class="o">(</span>SVM<span class="o">)</span><span class="w"> </span>capabilities<span class="w">        </span><span class="o">(</span>core<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-94" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-94" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-94"></a><span class="w">    </span>Coarse-grained<span class="w"> </span>buffer<span class="w"> </span>sharing<span class="w">                 </span>Yes
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-95" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-95" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-95"></a><span class="w">    </span>Fine-grained<span class="w"> </span>buffer<span class="w"> </span>sharing<span class="w">                   </span>No
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-96" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-96" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-96"></a><span class="w">    </span>Fine-grained<span class="w"> </span>system<span class="w"> </span>sharing<span class="w">                   </span>No
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-97" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-97" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-97"></a><span class="w">    </span>Atomics<span class="w">                                       </span>No
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-98" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-98" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-98"></a><span class="w">  </span>Minimum<span class="w"> </span>alignment<span class="w"> </span><span class="k">for</span><span class="w"> </span>any<span class="w"> </span>data<span class="w"> </span><span class="nb">type</span><span class="w">             </span><span class="m">128</span><span class="w"> </span>bytes
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-99" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-99" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-99"></a><span class="w">  </span>Alignment<span class="w"> </span>of<span class="w"> </span>base<span class="w"> </span>address<span class="w">                       </span><span class="m">1024</span><span class="w"> </span>bits<span class="w"> </span><span class="o">(</span><span class="m">128</span><span class="w"> </span>bytes<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-100" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-100" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-100"></a><span class="w">  </span>Preferred<span class="w"> </span>alignment<span class="w"> </span><span class="k">for</span><span class="w"> </span>atomics
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-101" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-101" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-101"></a><span class="w">    </span>SVM<span class="w">                                           </span><span class="m">0</span><span class="w"> </span>bytes
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-102" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-102" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-102"></a><span class="w">    </span>Global<span class="w">                                        </span><span class="m">0</span><span class="w"> </span>bytes
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-103" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-103" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-103"></a><span class="w">    </span>Local<span class="w">                                         </span><span class="m">0</span><span class="w"> </span>bytes
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-104" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-104" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-104"></a><span class="w">  </span>Max<span class="w"> </span>size<span class="w"> </span><span class="k">for</span><span class="w"> </span>global<span class="w"> </span>variable<span class="w">                    </span><span class="m">65536</span><span class="w"> </span><span class="o">(</span>64KiB<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-105" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-105" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-105"></a><span class="w">  </span>Preferred<span class="w"> </span>total<span class="w"> </span>size<span class="w"> </span>of<span class="w"> </span>global<span class="w"> </span>vars<span class="w">             </span><span class="m">0</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-106" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-106" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-106"></a><span class="w">  </span>Global<span class="w"> </span>Memory<span class="w"> </span>cache<span class="w"> </span><span class="nb">type</span><span class="w">                        </span>Read/Write
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-107" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-107" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-107"></a><span class="w">  </span>Global<span class="w"> </span>Memory<span class="w"> </span>cache<span class="w"> </span>size<span class="w">                        </span><span class="m">1048576</span><span class="w"> </span><span class="o">(</span>1024KiB<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-108" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-108" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-108"></a><span class="w">  </span>Global<span class="w"> </span>Memory<span class="w"> </span>cache<span class="w"> </span>line<span class="w"> </span>size<span class="w">                   </span><span class="m">64</span><span class="w"> </span>bytes
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-109" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-109" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-109"></a><span class="w">  </span>Image<span class="w"> </span>support<span class="w">                                   </span>Yes
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-110" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-110" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-110"></a><span class="w">    </span>Max<span class="w"> </span>number<span class="w"> </span>of<span class="w"> </span>samplers<span class="w"> </span>per<span class="w"> </span>kernel<span class="w">             </span><span class="m">16</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-111" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-111" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-111"></a><span class="w">    </span>Max<span class="w"> </span>size<span class="w"> </span><span class="k">for</span><span class="w"> </span>1D<span class="w"> </span>images<span class="w"> </span>from<span class="w"> </span>buffer<span class="w">            </span><span class="m">65536</span><span class="w"> </span>pixels
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-112" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-112" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-112"></a><span class="w">    </span>Max<span class="w"> </span>1D<span class="w"> </span>or<span class="w"> </span>2D<span class="w"> </span>image<span class="w"> </span>array<span class="w"> </span>size<span class="w">                 </span><span class="m">2048</span><span class="w"> </span>images
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-113" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-113" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-113"></a><span class="w">    </span>Base<span class="w"> </span>address<span class="w"> </span>alignment<span class="w"> </span><span class="k">for</span><span class="w"> </span>2D<span class="w"> </span>image<span class="w"> </span>buffers<span class="w">   </span><span class="m">32</span><span class="w"> </span>bytes
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-114" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-114" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-114"></a><span class="w">    </span>Pitch<span class="w"> </span>alignment<span class="w"> </span><span class="k">for</span><span class="w"> </span>2D<span class="w"> </span>image<span class="w"> </span>buffers<span class="w">          </span><span class="m">64</span><span class="w"> </span>pixels
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-115" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-115" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-115"></a><span class="w">    </span>Max<span class="w"> </span>2D<span class="w"> </span>image<span class="w"> </span>size<span class="w">                             </span>65536x65536<span class="w"> </span>pixels
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-116" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-116" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-116"></a><span class="w">    </span>Max<span class="w"> </span>3D<span class="w"> </span>image<span class="w"> </span>size<span class="w">                             </span>65536x65536x65536<span class="w"> </span>pixels
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-117" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-117" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-117"></a><span class="w">    </span>Max<span class="w"> </span>number<span class="w"> </span>of<span class="w"> </span><span class="nb">read</span><span class="w"> </span>image<span class="w"> </span>args<span class="w">                 </span><span class="m">128</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-118" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-118" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-118"></a><span class="w">    </span>Max<span class="w"> </span>number<span class="w"> </span>of<span class="w"> </span>write<span class="w"> </span>image<span class="w"> </span>args<span class="w">                </span><span class="m">64</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-119" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-119" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-119"></a><span class="w">    </span>Max<span class="w"> </span>number<span class="w"> </span>of<span class="w"> </span>read/write<span class="w"> </span>image<span class="w"> </span>args<span class="w">           </span><span class="m">64</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-120" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-120" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-120"></a><span class="w">  </span>Max<span class="w"> </span>number<span class="w"> </span>of<span class="w"> </span>pipe<span class="w"> </span>args<span class="w">                         </span><span class="m">16</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-121" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-121" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-121"></a><span class="w">  </span>Max<span class="w"> </span>active<span class="w"> </span>pipe<span class="w"> </span>reservations<span class="w">                    </span><span class="m">1</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-122" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-122" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-122"></a><span class="w">  </span>Max<span class="w"> </span>pipe<span class="w"> </span>packet<span class="w"> </span>size<span class="w">                            </span><span class="m">1024</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-123" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-123" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-123"></a><span class="w">  </span>Local<span class="w"> </span>memory<span class="w"> </span><span class="nb">type</span><span class="w">                               </span>Global
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-124" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-124" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-124"></a><span class="w">  </span>Local<span class="w"> </span>memory<span class="w"> </span>size<span class="w">                               </span><span class="m">32768</span><span class="w"> </span><span class="o">(</span>32KiB<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-125" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-125" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-125"></a><span class="w">  </span>Max<span class="w"> </span>number<span class="w"> </span>of<span class="w"> </span>constant<span class="w"> </span>args<span class="w">                     </span><span class="m">128</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-126" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-126" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-126"></a><span class="w">  </span>Max<span class="w"> </span>constant<span class="w"> </span>buffer<span class="w"> </span>size<span class="w">                        </span><span class="m">33327280128</span><span class="w"> </span><span class="o">(</span><span class="m">31</span>.04GiB<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-127" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-127" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-127"></a><span class="w">  </span>Max<span class="w"> </span>size<span class="w"> </span>of<span class="w"> </span>kernel<span class="w"> </span>argument<span class="w">                     </span><span class="m">1024</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-128" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-128" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-128"></a><span class="w">  </span>Queue<span class="w"> </span>properties<span class="w"> </span><span class="o">(</span>on<span class="w"> </span>host<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-129" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-129" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-129"></a><span class="w">    </span>Out-of-order<span class="w"> </span>execution<span class="w">                        </span>Yes
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-130" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-130" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-130"></a><span class="w">    </span>Profiling<span class="w">                                     </span>Yes
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-131" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-131" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-131"></a><span class="w">  </span>Queue<span class="w"> </span>properties<span class="w"> </span><span class="o">(</span>on<span class="w"> </span>device<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-132" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-132" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-132"></a><span class="w">    </span>Out-of-order<span class="w"> </span>execution<span class="w">                        </span>Yes
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-133" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-133" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-133"></a><span class="w">    </span>Profiling<span class="w">                                     </span>Yes
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-134" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-134" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-134"></a><span class="w">    </span>Preferred<span class="w"> </span>size<span class="w">                                </span><span class="m">2097152</span><span class="w"> </span><span class="o">(</span>2MiB<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-135" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-135" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-135"></a><span class="w">    </span>Max<span class="w"> </span>size<span class="w">                                      </span><span class="m">16777216</span><span class="w"> </span><span class="o">(</span>16MiB<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-136" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-136" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-136"></a><span class="w">  </span>Max<span class="w"> </span>queues<span class="w"> </span>on<span class="w"> </span>device<span class="w">                            </span><span class="m">1</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-137" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-137" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-137"></a><span class="w">  </span>Max<span class="w"> </span>events<span class="w"> </span>on<span class="w"> </span>device<span class="w">                            </span><span class="m">1024</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-138" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-138" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-138"></a><span class="w">  </span>Controlled<span class="w"> </span>termination<span class="w"> </span>caps.<span class="w"> </span><span class="o">(</span>ARM<span class="o">)</span><span class="w">              </span>Controlled<span class="w"> </span>Success,<span class="w"> </span>Controlled<span class="w"> </span>Failurure
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-139" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-139" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-139"></a><span class="w">  </span>Prefer<span class="w"> </span>user<span class="w"> </span>sync<span class="w"> </span><span class="k">for</span><span class="w"> </span>interop<span class="w">                    </span>No
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-140" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-140" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-140"></a><span class="w">  </span>Profiling<span class="w"> </span>timer<span class="w"> </span>resolution<span class="w">                      </span>1000ns
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-141" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-141" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-141"></a><span class="w">  </span>Execution<span class="w"> </span>capabilities
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-142" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-142" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-142"></a><span class="w">    </span>Run<span class="w"> </span>OpenCL<span class="w"> </span>kernels<span class="w">                            </span>Yes
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-143" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-143" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-143"></a><span class="w">    </span>Run<span class="w"> </span>native<span class="w"> </span>kernels<span class="w">                            </span>No
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-144" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-144" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-144"></a><span class="w">    </span>Sub-group<span class="w"> </span>independent<span class="w"> </span>forward<span class="w"> </span>progress<span class="w">        </span>Yes
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-145" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-145" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-145"></a><span class="w">    </span>Scheduling<span class="w"> </span>controls<span class="w"> </span><span class="o">(</span>ARM<span class="o">)</span><span class="w">                     </span>Kernel<span class="w"> </span>batching,<span class="w"> </span>Work-group<span class="w"> </span>batch<span class="w"> </span>size,<span class="w"> </span>Work-group<span class="w"> </span>batch<span class="w"> </span>size<span class="w"> </span>modifier,<span class="w"> </span>Register<span class="w"> </span>allocation
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-146" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-146" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-146"></a><span class="w">    </span>Supported<span class="w"> </span>reg<span class="w"> </span>allocs<span class="w"> </span><span class="o">(</span>ARM<span class="o">)</span><span class="w">                    </span><span class="m">32</span>,<span class="w"> </span><span class="m">64</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-147" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-147" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-147"></a><span class="w">    </span>Max<span class="w"> </span>warps/CU<span class="w"> </span><span class="o">(</span>ARM<span class="o">)</span><span class="w">                            </span>&lt;printDeviceInfo:211:<span class="w"> </span>get<span class="w"> </span>CL_DEVICE_MAX_WARP_COUNT_ARM<span class="w"> </span>:<span class="w"> </span>error<span class="w"> </span>-30&gt;
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-148" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-148" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-148"></a><span class="w">    </span>IL<span class="w"> </span>version<span class="w">                                    </span>SPIR-V_1.0
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-149" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-149" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-149"></a><span class="w">    </span>ILs<span class="w"> </span>with<span class="w"> </span>version<span class="w">                              </span>SPIR-V<span class="w">                                                           </span>0x400000<span class="w"> </span><span class="o">(</span><span class="m">1</span>.0.0<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-150" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-150" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-150"></a><span class="w">  </span>printf<span class="o">()</span><span class="w"> </span>buffer<span class="w"> </span>size<span class="w">                            </span><span class="m">1048576</span><span class="w"> </span><span class="o">(</span>1024KiB<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-151" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-151" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-151"></a><span class="w">  </span>Built-in<span class="w"> </span>kernels<span class="w">                                </span><span class="o">(</span>n/a<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-152" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-152" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-152"></a><span class="w">  </span>Built-in<span class="w"> </span>kernels<span class="w"> </span>with<span class="w"> </span>version<span class="w">                   </span><span class="o">(</span>n/a<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-153" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-153" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-153"></a><span class="w">  </span>Device<span class="w"> </span>Extensions<span class="w">                               </span>cl_khr_global_int32_base_atomics<span class="w"> </span>cl_khr_global_int32_extended_atomics<span class="w"> </span>cl_khr_local_int32_base_atomics<span class="w"> </span>cl_khr_local_int32_extended_atomics<span class="w"> </span>cl_khr_byte_addressable_store<span class="w"> </span>cl_khr_3d_image_writes<span class="w"> </span>cl_khr_int64_base_atomics<span class="w"> </span>cl_khr_int64_extended_atomics<span class="w"> </span>cl_khr_fp16<span class="w"> </span>cl_khr_icd<span class="w"> </span>cl_khr_egl_image<span class="w"> </span>cl_khr_image2d_from_buffer<span class="w"> </span>cl_khr_depth_images<span class="w"> </span>cl_khr_subgroups<span class="w"> </span>cl_khr_subgroup_extended_types<span class="w"> </span>cl_khr_subgroup_non_uniform_vote<span class="w"> </span>cl_khr_subgroup_ballot<span class="w"> </span>cl_khr_il_program<span class="w"> </span>cl_khr_priority_hints<span class="w"> </span>cl_khr_create_command_queue<span class="w"> </span>cl_khr_spirv_no_integer_wrap_decoration<span class="w"> </span>cl_khr_extended_versioning<span class="w"> </span>cl_khr_device_uuid<span class="w"> </span>cl_arm_core_id<span class="w"> </span>cl_arm_printf<span class="w"> </span>cl_arm_non_uniform_work_group_size<span class="w"> </span>cl_arm_import_memory<span class="w"> </span>cl_arm_import_memory_dma_buf<span class="w"> </span>cl_arm_import_memory_host<span class="w"> </span>cl_arm_integer_dot_product_int8<span class="w"> </span>cl_arm_integer_dot_product_accumulate_int8<span class="w"> </span>cl_arm_integer_dot_product_accumulate_saturate_int8<span class="w"> </span>cl_arm_scheduling_controls<span class="w"> </span>cl_arm_controlled_kernel_termination<span class="w"> </span>cl_ext_cxx_for_opencl
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-154" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-154" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-154"></a><span class="w">  </span>Device<span class="w"> </span>Extensions<span class="w"> </span>with<span class="w"> </span>Version<span class="w">                  </span>cl_khr_global_int32_base_atomics<span class="w">                                 </span>0x400000<span class="w"> </span><span class="o">(</span><span class="m">1</span>.0.0<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-155" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-155" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-155"></a><span class="w">                                                  </span>cl_khr_global_int32_extended_atomics<span class="w">                             </span>0x400000<span class="w"> </span><span class="o">(</span><span class="m">1</span>.0.0<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-156" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-156" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-156"></a><span class="w">                                                  </span>cl_khr_local_int32_base_atomics<span class="w">                                  </span>0x400000<span class="w"> </span><span class="o">(</span><span class="m">1</span>.0.0<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-157" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-157" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-157"></a><span class="w">                                                  </span>cl_khr_local_int32_extended_atomics<span class="w">                              </span>0x400000<span class="w"> </span><span class="o">(</span><span class="m">1</span>.0.0<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-158" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-158" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-158"></a><span class="w">                                                  </span>cl_khr_byte_addressable_store<span class="w">                                    </span>0x400000<span class="w"> </span><span class="o">(</span><span class="m">1</span>.0.0<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-159" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-159" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-159"></a><span class="w">                                                  </span>cl_khr_3d_image_writes<span class="w">                                           </span>0x400000<span class="w"> </span><span class="o">(</span><span class="m">1</span>.0.0<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-160" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-160" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-160"></a><span class="w">                                                  </span>cl_khr_int64_base_atomics<span class="w">                                        </span>0x400000<span class="w"> </span><span class="o">(</span><span class="m">1</span>.0.0<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-161" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-161" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-161"></a><span class="w">                                                  </span>cl_khr_int64_extended_atomics<span class="w">                                    </span>0x400000<span class="w"> </span><span class="o">(</span><span class="m">1</span>.0.0<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-162" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-162" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-162"></a><span class="w">                                                  </span>cl_khr_fp16<span class="w">                                                      </span>0x400000<span class="w"> </span><span class="o">(</span><span class="m">1</span>.0.0<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-163" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-163" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-163"></a><span class="w">                                                  </span>cl_khr_icd<span class="w">                                                       </span>0x400000<span class="w"> </span><span class="o">(</span><span class="m">1</span>.0.0<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-164" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-164" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-164"></a><span class="w">                                                  </span>cl_khr_egl_image<span class="w">                                                 </span>0x400000<span class="w"> </span><span class="o">(</span><span class="m">1</span>.0.0<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-165" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-165" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-165"></a><span class="w">                                                  </span>cl_khr_image2d_from_buffer<span class="w">                                       </span>0x400000<span class="w"> </span><span class="o">(</span><span class="m">1</span>.0.0<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-166" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-166" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-166"></a><span class="w">                                                  </span>cl_khr_depth_images<span class="w">                                              </span>0x400000<span class="w"> </span><span class="o">(</span><span class="m">1</span>.0.0<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-167" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-167" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-167"></a><span class="w">                                                  </span>cl_khr_subgroups<span class="w">                                                 </span>0x400000<span class="w"> </span><span class="o">(</span><span class="m">1</span>.0.0<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-168" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-168" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-168"></a><span class="w">                                                  </span>cl_khr_subgroup_extended_types<span class="w">                                   </span>0x400000<span class="w"> </span><span class="o">(</span><span class="m">1</span>.0.0<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-169" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-169" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-169"></a><span class="w">                                                  </span>cl_khr_subgroup_non_uniform_vote<span class="w">                                 </span>0x400000<span class="w"> </span><span class="o">(</span><span class="m">1</span>.0.0<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-170" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-170" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-170"></a><span class="w">                                                  </span>cl_khr_subgroup_ballot<span class="w">                                           </span>0x400000<span class="w"> </span><span class="o">(</span><span class="m">1</span>.0.0<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-171" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-171" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-171"></a><span class="w">                                                  </span>cl_khr_il_program<span class="w">                                                </span>0x400000<span class="w"> </span><span class="o">(</span><span class="m">1</span>.0.0<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-172" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-172" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-172"></a><span class="w">                                                  </span>cl_khr_priority_hints<span class="w">                                            </span>0x400000<span class="w"> </span><span class="o">(</span><span class="m">1</span>.0.0<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-173" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-173" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-173"></a><span class="w">                                                  </span>cl_khr_create_command_queue<span class="w">                                      </span>0x400000<span class="w"> </span><span class="o">(</span><span class="m">1</span>.0.0<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-174" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-174" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-174"></a><span class="w">                                                  </span>cl_khr_spirv_no_integer_wrap_decoration<span class="w">                          </span>0x400000<span class="w"> </span><span class="o">(</span><span class="m">1</span>.0.0<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-175" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-175" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-175"></a><span class="w">                                                  </span>cl_khr_extended_versioning<span class="w">                                       </span>0x400000<span class="w"> </span><span class="o">(</span><span class="m">1</span>.0.0<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-176" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-176" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-176"></a><span class="w">                                                  </span>cl_khr_device_uuid<span class="w">                                               </span>0x400000<span class="w"> </span><span class="o">(</span><span class="m">1</span>.0.0<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-177" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-177" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-177"></a><span class="w">                                                  </span>cl_arm_core_id<span class="w">                                                   </span>0x400000<span class="w"> </span><span class="o">(</span><span class="m">1</span>.0.0<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-178" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-178" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-178"></a><span class="w">                                                  </span>cl_arm_printf<span class="w">                                                    </span>0x400000<span class="w"> </span><span class="o">(</span><span class="m">1</span>.0.0<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-179" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-179" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-179"></a><span class="w">                                                  </span>cl_arm_non_uniform_work_group_size<span class="w">                               </span>0x400000<span class="w"> </span><span class="o">(</span><span class="m">1</span>.0.0<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-180" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-180" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-180"></a><span class="w">                                                  </span>cl_arm_import_memory<span class="w">                                             </span>0x400000<span class="w"> </span><span class="o">(</span><span class="m">1</span>.0.0<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-181" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-181" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-181"></a><span class="w">                                                  </span>cl_arm_import_memory_dma_buf<span class="w">                                     </span>0x400000<span class="w"> </span><span class="o">(</span><span class="m">1</span>.0.0<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-182" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-182" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-182"></a><span class="w">                                                  </span>cl_arm_import_memory_host<span class="w">                                        </span>0x400000<span class="w"> </span><span class="o">(</span><span class="m">1</span>.0.0<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-183" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-183" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-183"></a><span class="w">                                                  </span>cl_arm_integer_dot_product_int8<span class="w">                                  </span>0x400000<span class="w"> </span><span class="o">(</span><span class="m">1</span>.0.0<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-184" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-184" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-184"></a><span class="w">                                                  </span>cl_arm_integer_dot_product_accumulate_int8<span class="w">                       </span>0x400000<span class="w"> </span><span class="o">(</span><span class="m">1</span>.0.0<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-185" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-185" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-185"></a><span class="w">                                                  </span>cl_arm_integer_dot_product_accumulate_saturate_int8<span class="w">              </span>0x400000<span class="w"> </span><span class="o">(</span><span class="m">1</span>.0.0<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-186" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-186" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-186"></a><span class="w">                                                  </span>cl_arm_scheduling_controls<span class="w">                                         </span>0x3000<span class="w"> </span><span class="o">(</span><span class="m">0</span>.3.0<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-187" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-187" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-187"></a><span class="w">                                                  </span>cl_arm_controlled_kernel_termination<span class="w">                             </span>0x400000<span class="w"> </span><span class="o">(</span><span class="m">1</span>.0.0<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-188" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-188" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-188"></a><span class="w">                                                  </span>cl_ext_cxx_for_opencl<span class="w">                                            </span>0x400000<span class="w"> </span><span class="o">(</span><span class="m">1</span>.0.0<span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-189" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-189" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-189"></a>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-190" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-190" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-190"></a><span class="w">  </span>Platform<span class="w"> </span>Name<span class="w">                                   </span>Clover
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-191" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-191" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-191"></a>Number<span class="w"> </span>of<span class="w"> </span>devices<span class="w">                                 </span><span class="m">0</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-192" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-192" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-192"></a>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-193" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-193" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-193"></a><span class="w">  </span>Platform<span class="w"> </span>Name<span class="w">                                   </span>rusticl
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-194" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-194" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-194"></a>Number<span class="w"> </span>of<span class="w"> </span>devices<span class="w">                                 </span><span class="m">0</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-195" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-195" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-195"></a>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-196" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-196" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-196"></a>NULL<span class="w"> </span>platform<span class="w"> </span>behavior
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-197" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-197" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-197"></a><span class="w">  </span>clGetPlatformInfo<span class="o">(</span>NULL,<span class="w"> </span>CL_PLATFORM_NAME,<span class="w"> </span>...<span class="o">)</span><span class="w">  </span>ARM<span class="w"> </span>Platform
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-198" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-198" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-198"></a><span class="w">  </span>clGetDeviceIDs<span class="o">(</span>NULL,<span class="w"> </span>CL_DEVICE_TYPE_ALL,<span class="w"> </span>...<span class="o">)</span><span class="w">   </span>Success<span class="w"> </span><span class="o">[</span>ARM<span class="o">]</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-199" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-199" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-199"></a><span class="w">  </span>clCreateContext<span class="o">(</span>NULL,<span class="w"> </span>...<span class="o">)</span><span class="w"> </span><span class="o">[</span>default<span class="o">]</span><span class="w">            </span>Success<span class="w"> </span><span class="o">[</span>ARM<span class="o">]</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-200" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-200" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-200"></a><span class="w">  </span>clCreateContext<span class="o">(</span>NULL,<span class="w"> </span>...<span class="o">)</span><span class="w"> </span><span class="o">[</span>other<span class="o">]</span><span class="w">              </span>&lt;error:<span class="w"> </span>no<span class="w"> </span>devices<span class="w"> </span><span class="k">in</span><span class="w"> </span>non-default<span class="w"> </span>plaforms&gt;
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-201" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-201" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-201"></a><span class="w">  </span>clCreateContextFromType<span class="o">(</span>NULL,<span class="w"> </span>CL_DEVICE_TYPE_DEFAULT<span class="o">)</span><span class="w">  </span>Success<span class="w"> </span><span class="o">(</span><span class="m">1</span><span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-202" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-202" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-202"></a><span class="w">    </span>Platform<span class="w"> </span>Name<span class="w">                                 </span>ARM<span class="w"> </span>Platform
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-203" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-203" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-203"></a><span class="w">    </span>Device<span class="w"> </span>Name<span class="w">                                   </span>Mali-LODX<span class="w"> </span>r0p0
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-204" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-204" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-204"></a><span class="w">  </span>clCreateContextFromType<span class="o">(</span>NULL,<span class="w"> </span>CL_DEVICE_TYPE_CPU<span class="o">)</span><span class="w">  </span>No<span class="w"> </span>devices<span class="w"> </span>found<span class="w"> </span><span class="k">in</span><span class="w"> </span>platform
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-205" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-205" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-205"></a><span class="w">  </span>clCreateContextFromType<span class="o">(</span>NULL,<span class="w"> </span>CL_DEVICE_TYPE_GPU<span class="o">)</span><span class="w">  </span>Success<span class="w"> </span><span class="o">(</span><span class="m">1</span><span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-206" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-206" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-206"></a><span class="w">    </span>Platform<span class="w"> </span>Name<span class="w">                                 </span>ARM<span class="w"> </span>Platform
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-207" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-207" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-207"></a><span class="w">    </span>Device<span class="w"> </span>Name<span class="w">                                   </span>Mali-LODX<span class="w"> </span>r0p0
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-208" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-208" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-208"></a><span class="w">  </span>clCreateContextFromType<span class="o">(</span>NULL,<span class="w"> </span>CL_DEVICE_TYPE_ACCELERATOR<span class="o">)</span><span class="w">  </span>No<span class="w"> </span>devices<span class="w"> </span>found<span class="w"> </span><span class="k">in</span><span class="w"> </span>platform
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-209" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-209" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-209"></a><span class="w">  </span>clCreateContextFromType<span class="o">(</span>NULL,<span class="w"> </span>CL_DEVICE_TYPE_CUSTOM<span class="o">)</span><span class="w">  </span>No<span class="w"> </span>devices<span class="w"> </span>found<span class="w"> </span><span class="k">in</span><span class="w"> </span>platform
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-210" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-210" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-210"></a><span class="w">  </span>clCreateContextFromType<span class="o">(</span>NULL,<span class="w"> </span>CL_DEVICE_TYPE_ALL<span class="o">)</span><span class="w">  </span>Success<span class="w"> </span><span class="o">(</span><span class="m">1</span><span class="o">)</span>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-211" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-211" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-211"></a><span class="w">    </span>Platform<span class="w"> </span>Name<span class="w">                                 </span>ARM<span class="w"> </span>Platform
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-212" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-212" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-212"></a><span class="w">    </span>Device<span class="w"> </span>Name<span class="w">                                   </span>Mali-LODX<span class="w"> </span>r0p0
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-213" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-213" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-213"></a>
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-214" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-214" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-214"></a>ICD<span class="w"> </span>loader<span class="w"> </span>properties
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-215" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-215" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-215"></a><span class="w">  </span>ICD<span class="w"> </span>loader<span class="w"> </span>Name<span class="w">                                 </span>OpenCL<span class="w"> </span>ICD<span class="w"> </span>Loader
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-216" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-216" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-216"></a><span class="w">  </span>ICD<span class="w"> </span>loader<span class="w"> </span>Vendor<span class="w">                               </span>OCL<span class="w"> </span>Icd<span class="w"> </span>free<span class="w"> </span>software
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-217" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-217" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-217"></a><span class="w">  </span>ICD<span class="w"> </span>loader<span class="w"> </span>Version<span class="w">                              </span><span class="m">2</span>.3.1
<a id="rest_code_86c3755ccaa049f78a68d4ebc3876d72-218" name="rest_code_86c3755ccaa049f78a68d4ebc3876d72-218" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_86c3755ccaa049f78a68d4ebc3876d72-218"></a><span class="w">  </span>ICD<span class="w"> </span>loader<span class="w"> </span>Profile<span class="w">                              </span>OpenCL<span class="w"> </span><span class="m">3</span>.0
</pre></div>
</section><section id="installation-of-tvm-and-mlc-llm"><h2>Installation of TVM and MLC-LLM</h2>
<p>Now that the system part is working properly, install the Unity TVM compiler following the instructions on this page <a class="reference external" href="https://llm.mlc.ai/docs/install/tvm.html#install-tvm-unity">https://llm.mlc.ai/docs/install/tvm.html#install-tvm-unity</a>. Choose build from source. I did not use Conda as presented but chose to setup a virtual environment. Make sure you enable OpenCL by adding  the directive <em>set(USE_OPENCL ON)</em> in your config.cmake file.</p>
<p>Compilation of TVM can take a while, mine took roughly 30 minutes to compile. After compilation, the installable library is found in the <em>python</em> sub-directory. With the virtualenv activated, a simple <em>pip install .</em> should do the job.</p>
<p>Install the <a class="reference external" href="https://llm.mlc.ai/docs/install/mlc_llm.html">https://llm.mlc.ai/docs/install/mlc_llm.html</a> again, building from source and answering yes when asked if you want to build MLC-LLM with OpenCL support. The installation procedure is the same as for TVM.</p>
</section><section id="download-the-llama-3-model"><h2>Download the Llama 3 model</h2>
<p>Download the model for example from HuggingFace. You need both the instruct version <a class="reference external" href="https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct/">https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct/</a> and the file tokenizer.json from the full version of the Llama3 model <a class="reference external" href="https://huggingface.co/meta-llama/Meta-Llama-3-8B">https://huggingface.co/meta-llama/Meta-Llama-3-8B</a>.</p>
<p>You should now have the ingredients of the recipe, let’s start cooking!</p>
</section><section id="convert-the-weights"><h2>Convert the weights</h2>
<p>Convert the weights (it should take around 3 minutes for doing so) by issuing:</p>
<div class="code"><pre class="code shell"><a id="rest_code_39c9794068bc40f2b8fe4731d4527f45-1" name="rest_code_39c9794068bc40f2b8fe4731d4527f45-1" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_39c9794068bc40f2b8fe4731d4527f45-1"></a>mlc_llm<span class="w"> </span>convert_weight<span class="w"> </span>--quantization<span class="w"> </span>q4f16_1<span class="w"> </span>--device<span class="w"> </span>opencl<span class="w"> </span>--output<span class="w"> </span>Meta-Llama-3-8B-Instruct_MLC<span class="w"> </span>Meta-Llama-3-8B-Instruct/config.json
</pre></div>
<p>You shoud get the following output (this was truncated as the weight conversion is somewhat boring):</p>
<div class="code"><pre class="code shell"><a id="rest_code_bb655148f1e14a87bb6f314377462f8b-1" name="rest_code_bb655148f1e14a87bb6f314377462f8b-1" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_bb655148f1e14a87bb6f314377462f8b-1"></a>$<span class="w"> </span><span class="nb">time</span><span class="w"> </span>mlc_llm<span class="w"> </span>convert_weight<span class="w"> </span>--quantization<span class="w"> </span>q4f16_1<span class="w"> </span>--device<span class="w"> </span>opencl<span class="w"> </span>--output<span class="w"> </span>Meta-Llama-3-8B-Instruct_MLC<span class="w"> </span>Meta-Llama-3-8B-Instruct/config.json
<a id="rest_code_bb655148f1e14a87bb6f314377462f8b-2" name="rest_code_bb655148f1e14a87bb6f314377462f8b-2" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_bb655148f1e14a87bb6f314377462f8b-2"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">13</span>:56:31<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>auto_device.py:76:<span class="w"> </span>Found<span class="w"> </span>device:<span class="w"> </span>opencl:0
<a id="rest_code_bb655148f1e14a87bb6f314377462f8b-3" name="rest_code_bb655148f1e14a87bb6f314377462f8b-3" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_bb655148f1e14a87bb6f314377462f8b-3"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">13</span>:56:31<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>auto_config.py:115:<span class="w"> </span>Found<span class="w"> </span>model<span class="w"> </span>configuration:<span class="w"> </span>Meta-Llama-3-8B-Instruct/config.json
<a id="rest_code_bb655148f1e14a87bb6f314377462f8b-4" name="rest_code_bb655148f1e14a87bb6f314377462f8b-4" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_bb655148f1e14a87bb6f314377462f8b-4"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">13</span>:56:31<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>auto_weight.py:70:<span class="w"> </span>Finding<span class="w"> </span>weights<span class="w"> </span><span class="k">in</span>:<span class="w"> </span>Meta-Llama-3-8B-Instruct
<a id="rest_code_bb655148f1e14a87bb6f314377462f8b-5" name="rest_code_bb655148f1e14a87bb6f314377462f8b-5" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_bb655148f1e14a87bb6f314377462f8b-5"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">13</span>:56:31<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>auto_weight.py:136:<span class="w"> </span>Not<span class="w"> </span>found<span class="w"> </span>Huggingface<span class="w"> </span>PyTorch
<a id="rest_code_bb655148f1e14a87bb6f314377462f8b-6" name="rest_code_bb655148f1e14a87bb6f314377462f8b-6" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_bb655148f1e14a87bb6f314377462f8b-6"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">13</span>:56:31<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>auto_weight.py:143:<span class="w"> </span>Found<span class="w"> </span><span class="nb">source</span><span class="w"> </span>weight<span class="w"> </span>format:<span class="w"> </span>huggingface-safetensor.<span class="w"> </span>Source<span class="w"> </span>configuration:<span class="w"> </span>Meta-Llama-3-8B-Instruct/model.safetensors.index.json
<a id="rest_code_bb655148f1e14a87bb6f314377462f8b-7" name="rest_code_bb655148f1e14a87bb6f314377462f8b-7" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_bb655148f1e14a87bb6f314377462f8b-7"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">13</span>:56:31<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>auto_weight.py:106:<span class="w"> </span>Using<span class="w"> </span><span class="nb">source</span><span class="w"> </span>weight<span class="w"> </span>configuration:<span class="w"> </span>Meta-Llama-3-8B-Instruct/model.safetensors.index.json.<span class="w"> </span>Use<span class="w"> </span><span class="sb">`</span>--source<span class="sb">`</span><span class="w"> </span>to<span class="w"> </span>override.
<a id="rest_code_bb655148f1e14a87bb6f314377462f8b-8" name="rest_code_bb655148f1e14a87bb6f314377462f8b-8" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_bb655148f1e14a87bb6f314377462f8b-8"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">13</span>:56:31<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>auto_weight.py:110:<span class="w"> </span>Using<span class="w"> </span><span class="nb">source</span><span class="w"> </span>weight<span class="w"> </span>format:<span class="w"> </span>huggingface-safetensor.<span class="w"> </span>Use<span class="w"> </span><span class="sb">`</span>--source-format<span class="sb">`</span><span class="w"> </span>to<span class="w"> </span>override.
<a id="rest_code_bb655148f1e14a87bb6f314377462f8b-9" name="rest_code_bb655148f1e14a87bb6f314377462f8b-9" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_bb655148f1e14a87bb6f314377462f8b-9"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">13</span>:56:31<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>auto_config.py:153:<span class="w"> </span>Found<span class="w"> </span>model<span class="w"> </span>type:<span class="w"> </span>llama.<span class="w"> </span>Use<span class="w"> </span><span class="sb">`</span>--model-type<span class="sb">`</span><span class="w"> </span>to<span class="w"> </span>override.
<a id="rest_code_bb655148f1e14a87bb6f314377462f8b-10" name="rest_code_bb655148f1e14a87bb6f314377462f8b-10" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_bb655148f1e14a87bb6f314377462f8b-10"></a>Weight<span class="w"> </span>conversion<span class="w"> </span>with<span class="w"> </span>arguments:
<a id="rest_code_bb655148f1e14a87bb6f314377462f8b-11" name="rest_code_bb655148f1e14a87bb6f314377462f8b-11" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_bb655148f1e14a87bb6f314377462f8b-11"></a><span class="w">  </span>--config<span class="w">          </span>Meta-Llama-3-8B-Instruct/config.json
<a id="rest_code_bb655148f1e14a87bb6f314377462f8b-12" name="rest_code_bb655148f1e14a87bb6f314377462f8b-12" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_bb655148f1e14a87bb6f314377462f8b-12"></a><span class="w">  </span>--quantization<span class="w">    </span>GroupQuantize<span class="o">(</span><span class="nv">name</span><span class="o">=</span><span class="s1">'q4f16_1'</span>,<span class="w"> </span><span class="nv">kind</span><span class="o">=</span><span class="s1">'group-quant'</span>,<span class="w"> </span><span class="nv">group_size</span><span class="o">=</span><span class="m">32</span>,<span class="w"> </span><span class="nv">quantize_dtype</span><span class="o">=</span><span class="s1">'int4'</span>,<span class="w"> </span><span class="nv">storage_dtype</span><span class="o">=</span><span class="s1">'uint32'</span>,<span class="w"> </span><span class="nv">model_dtype</span><span class="o">=</span><span class="s1">'float16'</span>,<span class="w"> </span><span class="nv">linear_weight_layout</span><span class="o">=</span><span class="s1">'NK'</span>,<span class="w"> </span><span class="nv">quantize_embedding</span><span class="o">=</span>True,<span class="w"> </span><span class="nv">quantize_final_fc</span><span class="o">=</span>True,<span class="w"> </span><span class="nv">num_elem_per_storage</span><span class="o">=</span><span class="m">8</span>,<span class="w"> </span><span class="nv">num_storage_per_group</span><span class="o">=</span><span class="m">4</span>,<span class="w"> </span><span class="nv">max_int_value</span><span class="o">=</span><span class="m">7</span><span class="o">)</span>
<a id="rest_code_bb655148f1e14a87bb6f314377462f8b-13" name="rest_code_bb655148f1e14a87bb6f314377462f8b-13" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_bb655148f1e14a87bb6f314377462f8b-13"></a><span class="w">  </span>--model-type<span class="w">      </span>llama
<a id="rest_code_bb655148f1e14a87bb6f314377462f8b-14" name="rest_code_bb655148f1e14a87bb6f314377462f8b-14" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_bb655148f1e14a87bb6f314377462f8b-14"></a><span class="w">  </span>--device<span class="w">          </span>opencl:0
<a id="rest_code_bb655148f1e14a87bb6f314377462f8b-15" name="rest_code_bb655148f1e14a87bb6f314377462f8b-15" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_bb655148f1e14a87bb6f314377462f8b-15"></a><span class="w">  </span>--source<span class="w">          </span>Meta-Llama-3-8B-Instruct/model.safetensors.index.json
<a id="rest_code_bb655148f1e14a87bb6f314377462f8b-16" name="rest_code_bb655148f1e14a87bb6f314377462f8b-16" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_bb655148f1e14a87bb6f314377462f8b-16"></a><span class="w">  </span>--source-format<span class="w">   </span>huggingface-safetensor
<a id="rest_code_bb655148f1e14a87bb6f314377462f8b-17" name="rest_code_bb655148f1e14a87bb6f314377462f8b-17" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_bb655148f1e14a87bb6f314377462f8b-17"></a><span class="w">  </span>--output<span class="w">          </span>Meta-Llama-3-8B-Instruct_MLC
<a id="rest_code_bb655148f1e14a87bb6f314377462f8b-18" name="rest_code_bb655148f1e14a87bb6f314377462f8b-18" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_bb655148f1e14a87bb6f314377462f8b-18"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">13</span>:56:31<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>llama_model.py:52:<span class="w"> </span>context_window_size<span class="w"> </span>not<span class="w"> </span>found<span class="w"> </span><span class="k">in</span><span class="w"> </span>config.json.<span class="w"> </span>Falling<span class="w"> </span>back<span class="w"> </span>to<span class="w"> </span>max_position_embeddings<span class="w"> </span><span class="o">(</span><span class="m">8192</span><span class="o">)</span>
<a id="rest_code_bb655148f1e14a87bb6f314377462f8b-19" name="rest_code_bb655148f1e14a87bb6f314377462f8b-19" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_bb655148f1e14a87bb6f314377462f8b-19"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">13</span>:56:31<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>llama_model.py:72:<span class="w"> </span>prefill_chunk_size<span class="w"> </span>defaults<span class="w"> </span>to<span class="w"> </span>context_window_size<span class="w"> </span><span class="o">(</span><span class="m">8192</span><span class="o">)</span>
<a id="rest_code_bb655148f1e14a87bb6f314377462f8b-20" name="rest_code_bb655148f1e14a87bb6f314377462f8b-20" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_bb655148f1e14a87bb6f314377462f8b-20"></a>Start<span class="w"> </span>storing<span class="w"> </span>to<span class="w"> </span>cache<span class="w"> </span>Meta-Llama-3-8B-Instruct_MLC
<a id="rest_code_bb655148f1e14a87bb6f314377462f8b-21" name="rest_code_bb655148f1e14a87bb6f314377462f8b-21" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_bb655148f1e14a87bb6f314377462f8b-21"></a>arm_release_ver<span class="w"> </span>of<span class="w"> </span>this<span class="w"> </span>libmali<span class="w"> </span>is<span class="w"> </span><span class="s1">'g6p0-01eac0'</span>,<span class="w"> </span>rk_so_ver<span class="w"> </span>is<span class="w"> </span><span class="s1">'7'</span>.
<a id="rest_code_bb655148f1e14a87bb6f314377462f8b-22" name="rest_code_bb655148f1e14a87bb6f314377462f8b-22" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_bb655148f1e14a87bb6f314377462f8b-22"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">13</span>:56:38<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>huggingface_loader.py:182:<span class="w"> </span>Loading<span class="w"> </span>HF<span class="w"> </span>parameters<span class="w"> </span>from:<span class="w"> </span>Meta-Llama-3-8B-Instruct/model-00004-of-00004.safetensors
<a id="rest_code_bb655148f1e14a87bb6f314377462f8b-23" name="rest_code_bb655148f1e14a87bb6f314377462f8b-23" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_bb655148f1e14a87bb6f314377462f8b-23"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">13</span>:56:45<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>group_quantization.py:232:<span class="w"> </span>Compiling<span class="w"> </span>quantize<span class="w"> </span><span class="k">function</span><span class="w"> </span><span class="k">for</span><span class="w"> </span>key:<span class="w"> </span><span class="o">((</span><span class="m">128256</span>,<span class="w"> </span><span class="m">4096</span><span class="o">)</span>,<span class="w"> </span>float16,<span class="w"> </span>opencl,<span class="w"> </span><span class="nv">axis</span><span class="o">=</span><span class="m">1</span>,<span class="w"> </span><span class="nv">output_transpose</span><span class="o">=</span>False<span class="o">)</span>
<a id="rest_code_bb655148f1e14a87bb6f314377462f8b-24" name="rest_code_bb655148f1e14a87bb6f314377462f8b-24" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_bb655148f1e14a87bb6f314377462f8b-24"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">13</span>:56:47<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>huggingface_loader.py:164:<span class="w"> </span><span class="o">[</span>Quantized<span class="o">]</span><span class="w"> </span>Parameter:<span class="w"> </span><span class="s2">"lm_head.q_weight"</span>,<span class="w"> </span>shape:<span class="w"> </span><span class="o">(</span><span class="m">128256</span>,<span class="w"> </span><span class="m">512</span><span class="o">)</span>,<span class="w"> </span>dtype:<span class="w"> </span>uint32
<a id="rest_code_bb655148f1e14a87bb6f314377462f8b-25" name="rest_code_bb655148f1e14a87bb6f314377462f8b-25" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_bb655148f1e14a87bb6f314377462f8b-25"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">13</span>:56:48<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>huggingface_loader.py:164:<span class="w"> </span><span class="o">[</span>Quantized<span class="o">]</span><span class="w"> </span>Parameter:<span class="w"> </span><span class="s2">"lm_head.q_scale"</span>,<span class="w"> </span>shape:<span class="w"> </span><span class="o">(</span><span class="m">128256</span>,<span class="w"> </span><span class="m">128</span><span class="o">)</span>,<span class="w"> </span>dtype:<span class="w"> </span>float16
<a id="rest_code_bb655148f1e14a87bb6f314377462f8b-26" name="rest_code_bb655148f1e14a87bb6f314377462f8b-26" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_bb655148f1e14a87bb6f314377462f8b-26"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">13</span>:56:48<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>huggingface_loader.py:172:<span class="w"> </span><span class="o">[</span>Not<span class="w"> </span>quantized<span class="o">]</span><span class="w"> </span>Parameter:<span class="w"> </span><span class="s2">"model.layers.31.input_layernorm.weight"</span>,<span class="w"> </span>shape:<span class="w"> </span><span class="o">(</span><span class="m">4096</span>,<span class="o">)</span>,<span class="w"> </span>dtype:<span class="w"> </span>float16
<a id="rest_code_bb655148f1e14a87bb6f314377462f8b-27" name="rest_code_bb655148f1e14a87bb6f314377462f8b-27" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_bb655148f1e14a87bb6f314377462f8b-27"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">13</span>:56:49<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>group_quantization.py:232:<span class="w"> </span>Compiling<span class="w"> </span>quantize<span class="w"> </span><span class="k">function</span><span class="w"> </span><span class="k">for</span><span class="w"> </span>key:<span class="w"> </span><span class="o">((</span><span class="m">4096</span>,<span class="w"> </span><span class="m">14336</span><span class="o">)</span>,<span class="w"> </span>float16,<span class="w"> </span>opencl,<span class="w"> </span><span class="nv">axis</span><span class="o">=</span><span class="m">1</span>,<span class="w"> </span><span class="nv">output_transpose</span><span class="o">=</span>False<span class="o">)</span>
<a id="rest_code_bb655148f1e14a87bb6f314377462f8b-28" name="rest_code_bb655148f1e14a87bb6f314377462f8b-28" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_bb655148f1e14a87bb6f314377462f8b-28"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">13</span>:56:50<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>huggingface_loader.py:164:<span class="w"> </span><span class="o">[</span>Quantized<span class="o">]</span><span class="w"> </span>Parameter:<span class="w"> </span><span class="s2">"model.layers.31.mlp.down_proj.q_weight"</span>,<span class="w"> </span>shape:<span class="w"> </span><span class="o">(</span><span class="m">4096</span>,<span class="w"> </span><span class="m">1792</span><span class="o">)</span>,<span class="w"> </span>dtype:<span class="w"> </span>uint32
<a id="rest_code_bb655148f1e14a87bb6f314377462f8b-29" name="rest_code_bb655148f1e14a87bb6f314377462f8b-29" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_bb655148f1e14a87bb6f314377462f8b-29"></a><span class="o">[</span>...<span class="o">]</span>
<a id="rest_code_bb655148f1e14a87bb6f314377462f8b-30" name="rest_code_bb655148f1e14a87bb6f314377462f8b-30" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_bb655148f1e14a87bb6f314377462f8b-30"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">13</span>:58:55<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>huggingface_loader.py:194:<span class="w"> </span>Unloading<span class="w"> </span>HF<span class="w"> </span>weight<span class="w"> </span>file:<span class="w"> </span>Meta-Llama-3-8B-Instruct/model-00002-of-00004.safetensors
<a id="rest_code_bb655148f1e14a87bb6f314377462f8b-31" name="rest_code_bb655148f1e14a87bb6f314377462f8b-31" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_bb655148f1e14a87bb6f314377462f8b-31"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">13</span>:58:57<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>huggingface_loader.py:194:<span class="w"> </span>Unloading<span class="w"> </span>HF<span class="w"> </span>weight<span class="w"> </span>file:<span class="w"> </span>Meta-Llama-3-8B-Instruct/model-00003-of-00004.safetensors
<a id="rest_code_bb655148f1e14a87bb6f314377462f8b-32" name="rest_code_bb655148f1e14a87bb6f314377462f8b-32" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_bb655148f1e14a87bb6f314377462f8b-32"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">13</span>:58:58<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>stats.py:76:<span class="w"> </span>Time<span class="w"> </span>usage:<span class="w"> </span>HF<span class="w"> </span>loading:<span class="w"> </span><span class="m">19</span>.166<span class="w"> </span>sec<span class="p">;</span><span class="w"> </span>Pre-quantization<span class="w"> </span>mapping:<span class="w"> </span><span class="m">62</span>.397<span class="w"> </span>sec<span class="p">;</span><span class="w"> </span>Quantization:<span class="w"> </span><span class="m">17</span>.402<span class="w"> </span>sec
<a id="rest_code_bb655148f1e14a87bb6f314377462f8b-33" name="rest_code_bb655148f1e14a87bb6f314377462f8b-33" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_bb655148f1e14a87bb6f314377462f8b-33"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">13</span>:58:58<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>stats.py:90:<span class="w"> </span>RAM<span class="w"> </span>usage:<span class="w"> </span>Peak<span class="w"> </span>RAM:<span class="w"> </span><span class="m">18</span>.469<span class="w"> </span>GB.<span class="w"> </span>Total<span class="w"> </span>bytes<span class="w"> </span>loaded<span class="w"> </span>from<span class="w"> </span>disk:<span class="w"> </span><span class="m">29</span>.915<span class="w"> </span>GB
<a id="rest_code_bb655148f1e14a87bb6f314377462f8b-34" name="rest_code_bb655148f1e14a87bb6f314377462f8b-34" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_bb655148f1e14a87bb6f314377462f8b-34"></a>
<a id="rest_code_bb655148f1e14a87bb6f314377462f8b-35" name="rest_code_bb655148f1e14a87bb6f314377462f8b-35" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_bb655148f1e14a87bb6f314377462f8b-35"></a>All<span class="w"> </span>finished,<span class="w"> </span><span class="m">108</span><span class="w"> </span>total<span class="w"> </span>shards<span class="w"> </span>committed,<span class="w"> </span>record<span class="w"> </span>saved<span class="w"> </span>to<span class="w"> </span>Meta-Llama-3-8B-Instruct_MLC/ndarray-cache.json
<a id="rest_code_bb655148f1e14a87bb6f314377462f8b-36" name="rest_code_bb655148f1e14a87bb6f314377462f8b-36" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_bb655148f1e14a87bb6f314377462f8b-36"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">13</span>:58:58<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>convert_weight.py:156:<span class="w"> </span>Parameter<span class="w"> </span>size<span class="w"> </span>after<span class="w"> </span>quantization:<span class="w"> </span><span class="m">4</span>.207<span class="w"> </span>GB
<a id="rest_code_bb655148f1e14a87bb6f314377462f8b-37" name="rest_code_bb655148f1e14a87bb6f314377462f8b-37" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_bb655148f1e14a87bb6f314377462f8b-37"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">13</span>:58:58<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>convert_weight.py:161:<span class="w"> </span>Total<span class="w"> </span>parameters:<span class="w"> </span><span class="m">8</span>,030,261,248
<a id="rest_code_bb655148f1e14a87bb6f314377462f8b-38" name="rest_code_bb655148f1e14a87bb6f314377462f8b-38" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_bb655148f1e14a87bb6f314377462f8b-38"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">13</span>:58:58<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>convert_weight.py:162:<span class="w"> </span>Bits<span class="w"> </span>per<span class="w"> </span>parameter:<span class="w"> </span><span class="m">4</span>.500
<a id="rest_code_bb655148f1e14a87bb6f314377462f8b-39" name="rest_code_bb655148f1e14a87bb6f314377462f8b-39" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_bb655148f1e14a87bb6f314377462f8b-39"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">13</span>:58:58<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>convert_weight.py:167:<span class="w"> </span>Saved<span class="w"> </span>to<span class="w"> </span>directory:<span class="w"> </span>Meta-Llama-3-8B-Instruct_MLC
<a id="rest_code_bb655148f1e14a87bb6f314377462f8b-40" name="rest_code_bb655148f1e14a87bb6f314377462f8b-40" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_bb655148f1e14a87bb6f314377462f8b-40"></a>
<a id="rest_code_bb655148f1e14a87bb6f314377462f8b-41" name="rest_code_bb655148f1e14a87bb6f314377462f8b-41" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_bb655148f1e14a87bb6f314377462f8b-41"></a>real<span class="w">        </span>2m32.892s
<a id="rest_code_bb655148f1e14a87bb6f314377462f8b-42" name="rest_code_bb655148f1e14a87bb6f314377462f8b-42" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_bb655148f1e14a87bb6f314377462f8b-42"></a>user<span class="w">        </span>2m4.460s
<a id="rest_code_bb655148f1e14a87bb6f314377462f8b-43" name="rest_code_bb655148f1e14a87bb6f314377462f8b-43" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_bb655148f1e14a87bb6f314377462f8b-43"></a>sys<span class="w"> </span>1m37.346s
</pre></div>
<p>As you can see, the quantization is consuming a fair amount of memory, hence explaining the caveat above regarding the memory of your own SBC, should you use one.</p>
<div class="code"><pre class="code shell"><a id="rest_code_d8ebb3c6d8454735aebcc2187a5d35c6-1" name="rest_code_d8ebb3c6d8454735aebcc2187a5d35c6-1" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_d8ebb3c6d8454735aebcc2187a5d35c6-1"></a>RAM<span class="w"> </span>usage:<span class="w"> </span>Peak<span class="w"> </span>RAM:<span class="w"> </span><span class="m">18</span>.469<span class="w"> </span>GB.<span class="w"> </span>Total<span class="w"> </span>bytes<span class="w"> </span>loaded<span class="w"> </span>from<span class="w"> </span>disk:<span class="w"> </span><span class="m">29</span>.915<span class="w"> </span>GB
</pre></div>
</section><section id="config-generation"><h2>Config generation</h2>
<p>Generate config (it is nearly instantaneous). Note that I use the configuration for Llama2 but it doesn’t seem to be harmful at this stage. However, I guess some of the errors I have later on are related to this and may prompt for some adjustments:</p>
<div class="code"><pre class="code shell"><a id="rest_code_a9f22d38bb3e43d3b27d12cac8a33b63-1" name="rest_code_a9f22d38bb3e43d3b27d12cac8a33b63-1" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_a9f22d38bb3e43d3b27d12cac8a33b63-1"></a>mlc_llm<span class="w"> </span>gen_config<span class="w"> </span>--quantization<span class="w"> </span>q4f16_1<span class="w"> </span>--output<span class="w"> </span>Meta-Llama-3-8B-Instruct_MLC<span class="w"> </span>--conv-template<span class="w"> </span>llama-2<span class="w"> </span>Meta-Llama-3-8B-Instruct/config.json
</pre></div>
<p>Again this should get you with the following output:</p>
<div class="code"><pre class="code shell"><a id="rest_code_3969bc79e8774bebb2af89badaad76ab-1" name="rest_code_3969bc79e8774bebb2af89badaad76ab-1" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_3969bc79e8774bebb2af89badaad76ab-1"></a>$<span class="w"> </span><span class="nb">time</span><span class="w"> </span>mlc_llm<span class="w"> </span>gen_config<span class="w"> </span>--quantization<span class="w"> </span>q4f16_1<span class="w"> </span>--output<span class="w"> </span>Meta-Llama-3-8B-Instruct_MLC<span class="w"> </span>--conv-template<span class="w"> </span>llama-2<span class="w"> </span>Meta-Llama-3-8B-Instruct/config.json
<a id="rest_code_3969bc79e8774bebb2af89badaad76ab-2" name="rest_code_3969bc79e8774bebb2af89badaad76ab-2" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_3969bc79e8774bebb2af89badaad76ab-2"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">14</span>:04:28<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>auto_config.py:115:<span class="w"> </span>Found<span class="w"> </span>model<span class="w"> </span>configuration:<span class="w"> </span>Meta-Llama-3-8B-Instruct/config.json
<a id="rest_code_3969bc79e8774bebb2af89badaad76ab-3" name="rest_code_3969bc79e8774bebb2af89badaad76ab-3" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_3969bc79e8774bebb2af89badaad76ab-3"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">14</span>:04:28<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>auto_config.py:153:<span class="w"> </span>Found<span class="w"> </span>model<span class="w"> </span>type:<span class="w"> </span>llama.<span class="w"> </span>Use<span class="w"> </span><span class="sb">`</span>--model-type<span class="sb">`</span><span class="w"> </span>to<span class="w"> </span>override.
<a id="rest_code_3969bc79e8774bebb2af89badaad76ab-4" name="rest_code_3969bc79e8774bebb2af89badaad76ab-4" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_3969bc79e8774bebb2af89badaad76ab-4"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">14</span>:04:28<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>llama_model.py:52:<span class="w"> </span>context_window_size<span class="w"> </span>not<span class="w"> </span>found<span class="w"> </span><span class="k">in</span><span class="w"> </span>config.json.<span class="w"> </span>Falling<span class="w"> </span>back<span class="w"> </span>to<span class="w"> </span>max_position_embeddings<span class="w"> </span><span class="o">(</span><span class="m">8192</span><span class="o">)</span>
<a id="rest_code_3969bc79e8774bebb2af89badaad76ab-5" name="rest_code_3969bc79e8774bebb2af89badaad76ab-5" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_3969bc79e8774bebb2af89badaad76ab-5"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">14</span>:04:28<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>llama_model.py:72:<span class="w"> </span>prefill_chunk_size<span class="w"> </span>defaults<span class="w"> </span>to<span class="w"> </span>context_window_size<span class="w"> </span><span class="o">(</span><span class="m">8192</span><span class="o">)</span>
<a id="rest_code_3969bc79e8774bebb2af89badaad76ab-6" name="rest_code_3969bc79e8774bebb2af89badaad76ab-6" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_3969bc79e8774bebb2af89badaad76ab-6"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">14</span>:04:28<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>config.py:106:<span class="w"> </span>Overriding<span class="w"> </span>max_batch_size<span class="w"> </span>from<span class="w"> </span><span class="m">1</span><span class="w"> </span>to<span class="w"> </span><span class="m">80</span>
<a id="rest_code_3969bc79e8774bebb2af89badaad76ab-7" name="rest_code_3969bc79e8774bebb2af89badaad76ab-7" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_3969bc79e8774bebb2af89badaad76ab-7"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">14</span>:04:28<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>gen_config.py:121:<span class="w"> </span><span class="o">[</span>generation_config.json<span class="o">]</span><span class="w"> </span>Setting<span class="w"> </span>bos_token_id:<span class="w"> </span><span class="m">128000</span>
<a id="rest_code_3969bc79e8774bebb2af89badaad76ab-8" name="rest_code_3969bc79e8774bebb2af89badaad76ab-8" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_3969bc79e8774bebb2af89badaad76ab-8"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">14</span>:04:28<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>gen_config.py:121:<span class="w"> </span><span class="o">[</span>generation_config.json<span class="o">]</span><span class="w"> </span>Setting<span class="w"> </span>eos_token_id:<span class="w"> </span><span class="m">128001</span>
<a id="rest_code_3969bc79e8774bebb2af89badaad76ab-9" name="rest_code_3969bc79e8774bebb2af89badaad76ab-9" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_3969bc79e8774bebb2af89badaad76ab-9"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">14</span>:04:28<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>gen_config.py:133:<span class="w"> </span>Found<span class="w"> </span>tokenizer<span class="w"> </span>config:<span class="w"> </span>Meta-Llama-3-8B-Instruct/tokenizer.model.<span class="w"> </span>Copying<span class="w"> </span>to<span class="w"> </span>Meta-Llama-3-8B-Instruct_MLC/tokenizer.model
<a id="rest_code_3969bc79e8774bebb2af89badaad76ab-10" name="rest_code_3969bc79e8774bebb2af89badaad76ab-10" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_3969bc79e8774bebb2af89badaad76ab-10"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">14</span>:04:28<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>gen_config.py:133:<span class="w"> </span>Found<span class="w"> </span>tokenizer<span class="w"> </span>config:<span class="w"> </span>Meta-Llama-3-8B-Instruct/tokenizer.json.<span class="w"> </span>Copying<span class="w"> </span>to<span class="w"> </span>Meta-Llama-3-8B-Instruct_MLC/tokenizer.json
<a id="rest_code_3969bc79e8774bebb2af89badaad76ab-11" name="rest_code_3969bc79e8774bebb2af89badaad76ab-11" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_3969bc79e8774bebb2af89badaad76ab-11"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">14</span>:04:28<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>gen_config.py:135:<span class="w"> </span>Not<span class="w"> </span>found<span class="w"> </span>tokenizer<span class="w"> </span>config:<span class="w"> </span>Meta-Llama-3-8B-Instruct/vocab.json
<a id="rest_code_3969bc79e8774bebb2af89badaad76ab-12" name="rest_code_3969bc79e8774bebb2af89badaad76ab-12" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_3969bc79e8774bebb2af89badaad76ab-12"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">14</span>:04:28<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>gen_config.py:135:<span class="w"> </span>Not<span class="w"> </span>found<span class="w"> </span>tokenizer<span class="w"> </span>config:<span class="w"> </span>Meta-Llama-3-8B-Instruct/merges.txt
<a id="rest_code_3969bc79e8774bebb2af89badaad76ab-13" name="rest_code_3969bc79e8774bebb2af89badaad76ab-13" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_3969bc79e8774bebb2af89badaad76ab-13"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">14</span>:04:28<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>gen_config.py:135:<span class="w"> </span>Not<span class="w"> </span>found<span class="w"> </span>tokenizer<span class="w"> </span>config:<span class="w"> </span>Meta-Llama-3-8B-Instruct/added_tokens.json
<a id="rest_code_3969bc79e8774bebb2af89badaad76ab-14" name="rest_code_3969bc79e8774bebb2af89badaad76ab-14" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_3969bc79e8774bebb2af89badaad76ab-14"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">14</span>:04:28<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>gen_config.py:133:<span class="w"> </span>Found<span class="w"> </span>tokenizer<span class="w"> </span>config:<span class="w"> </span>Meta-Llama-3-8B-Instruct/tokenizer_config.json.<span class="w"> </span>Copying<span class="w"> </span>to<span class="w"> </span>Meta-Llama-3-8B-Instruct_MLC/tokenizer_config.json
<a id="rest_code_3969bc79e8774bebb2af89badaad76ab-15" name="rest_code_3969bc79e8774bebb2af89badaad76ab-15" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_3969bc79e8774bebb2af89badaad76ab-15"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">14</span>:04:28<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>gen_config.py:74:<span class="w"> </span><span class="o">[</span>System<span class="w"> </span>default<span class="o">]</span><span class="w"> </span>Setting<span class="w"> </span>pad_token_id:<span class="w"> </span><span class="m">0</span>
<a id="rest_code_3969bc79e8774bebb2af89badaad76ab-16" name="rest_code_3969bc79e8774bebb2af89badaad76ab-16" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_3969bc79e8774bebb2af89badaad76ab-16"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">14</span>:04:28<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>gen_config.py:74:<span class="w"> </span><span class="o">[</span>System<span class="w"> </span>default<span class="o">]</span><span class="w"> </span>Setting<span class="w"> </span>temperature:<span class="w"> </span><span class="m">0</span>.7
<a id="rest_code_3969bc79e8774bebb2af89badaad76ab-17" name="rest_code_3969bc79e8774bebb2af89badaad76ab-17" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_3969bc79e8774bebb2af89badaad76ab-17"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">14</span>:04:28<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>gen_config.py:74:<span class="w"> </span><span class="o">[</span>System<span class="w"> </span>default<span class="o">]</span><span class="w"> </span>Setting<span class="w"> </span>presence_penalty:<span class="w"> </span><span class="m">0</span>.0
<a id="rest_code_3969bc79e8774bebb2af89badaad76ab-18" name="rest_code_3969bc79e8774bebb2af89badaad76ab-18" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_3969bc79e8774bebb2af89badaad76ab-18"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">14</span>:04:28<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>gen_config.py:74:<span class="w"> </span><span class="o">[</span>System<span class="w"> </span>default<span class="o">]</span><span class="w"> </span>Setting<span class="w"> </span>frequency_penalty:<span class="w"> </span><span class="m">0</span>.0
<a id="rest_code_3969bc79e8774bebb2af89badaad76ab-19" name="rest_code_3969bc79e8774bebb2af89badaad76ab-19" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_3969bc79e8774bebb2af89badaad76ab-19"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">14</span>:04:28<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>gen_config.py:74:<span class="w"> </span><span class="o">[</span>System<span class="w"> </span>default<span class="o">]</span><span class="w"> </span>Setting<span class="w"> </span>repetition_penalty:<span class="w"> </span><span class="m">1</span>.0
<a id="rest_code_3969bc79e8774bebb2af89badaad76ab-20" name="rest_code_3969bc79e8774bebb2af89badaad76ab-20" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_3969bc79e8774bebb2af89badaad76ab-20"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">14</span>:04:28<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>gen_config.py:74:<span class="w"> </span><span class="o">[</span>System<span class="w"> </span>default<span class="o">]</span><span class="w"> </span>Setting<span class="w"> </span>top_p:<span class="w"> </span><span class="m">0</span>.95
<a id="rest_code_3969bc79e8774bebb2af89badaad76ab-21" name="rest_code_3969bc79e8774bebb2af89badaad76ab-21" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_3969bc79e8774bebb2af89badaad76ab-21"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">14</span>:04:28<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>gen_config.py:74:<span class="w"> </span><span class="o">[</span>System<span class="w"> </span>default<span class="o">]</span><span class="w"> </span>Setting<span class="w"> </span>mean_gen_len:<span class="w"> </span><span class="m">128</span>
<a id="rest_code_3969bc79e8774bebb2af89badaad76ab-22" name="rest_code_3969bc79e8774bebb2af89badaad76ab-22" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_3969bc79e8774bebb2af89badaad76ab-22"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">14</span>:04:28<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>gen_config.py:74:<span class="w"> </span><span class="o">[</span>System<span class="w"> </span>default<span class="o">]</span><span class="w"> </span>Setting<span class="w"> </span>max_gen_len:<span class="w"> </span><span class="m">512</span>
<a id="rest_code_3969bc79e8774bebb2af89badaad76ab-23" name="rest_code_3969bc79e8774bebb2af89badaad76ab-23" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_3969bc79e8774bebb2af89badaad76ab-23"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">14</span>:04:28<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>gen_config.py:74:<span class="w"> </span><span class="o">[</span>System<span class="w"> </span>default<span class="o">]</span><span class="w"> </span>Setting<span class="w"> </span>shift_fill_factor:<span class="w"> </span><span class="m">0</span>.3
<a id="rest_code_3969bc79e8774bebb2af89badaad76ab-24" name="rest_code_3969bc79e8774bebb2af89badaad76ab-24" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_3969bc79e8774bebb2af89badaad76ab-24"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">14</span>:04:28<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>gen_config.py:186:<span class="w"> </span>Dumping<span class="w"> </span>configuration<span class="w"> </span>file<span class="w"> </span>to:<span class="w"> </span>Meta-Llama-3-8B-Instruct_MLC/mlc-chat-config.json
</pre></div>
<p>The directory Meta-Llama-3-8B-Instructcontaining the source model can be disposed from now on, if you’re short on disk space.</p>
<p>Compile the native library (it should only take around two minutes):</p>
<div class="code"><pre class="code shell"><a id="rest_code_6f74a2c3e5ed4fc7b6c0a17dc3c90eaf-1" name="rest_code_6f74a2c3e5ed4fc7b6c0a17dc3c90eaf-1" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_6f74a2c3e5ed4fc7b6c0a17dc3c90eaf-1"></a>mlc_llm<span class="w"> </span>compile<span class="w"> </span>--quantization<span class="w"> </span>q4f16_1<span class="w"> </span>--device<span class="w"> </span>opencl<span class="w"> </span>--output<span class="w"> </span>Meta-Llama-3-8B-Instruct_MLC/Meta-Llama-3-8B-Instruct-opencl.so<span class="w"> </span>Meta-Llama-3-8B-Instruct_MLC/mlc-chat-config.json
</pre></div>
<p>The output should be similar to:</p>
<div class="code"><pre class="code shell"><a id="rest_code_1c0d9114a80d4060ab32deae1f804eef-1" name="rest_code_1c0d9114a80d4060ab32deae1f804eef-1" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_1c0d9114a80d4060ab32deae1f804eef-1"></a><span class="nb">time</span><span class="w"> </span>mlc_llm<span class="w"> </span>compile<span class="w"> </span>--quantization<span class="w"> </span>q4f16_1<span class="w"> </span>--device<span class="w"> </span>opencl<span class="w"> </span>--output<span class="w"> </span>Meta-Llama-3-8B-Instruct_MLC/Meta-Llama-3-8B-Instruct-opencl.so<span class="w"> </span>Meta-Llama-3-8B-Instruct_MLC/mlc-chat-config.json
<a id="rest_code_1c0d9114a80d4060ab32deae1f804eef-2" name="rest_code_1c0d9114a80d4060ab32deae1f804eef-2" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_1c0d9114a80d4060ab32deae1f804eef-2"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">14</span>:07:52<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>auto_config.py:69:<span class="w"> </span>Found<span class="w"> </span>model<span class="w"> </span>configuration:<span class="w"> </span>Meta-Llama-3-8B-Instruct_MLC/mlc-chat-config.json
<a id="rest_code_1c0d9114a80d4060ab32deae1f804eef-3" name="rest_code_1c0d9114a80d4060ab32deae1f804eef-3" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_1c0d9114a80d4060ab32deae1f804eef-3"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">14</span>:07:52<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>auto_target.py:102:<span class="w"> </span>Found<span class="w"> </span>host<span class="w"> </span>LLVM<span class="w"> </span>triple:<span class="w"> </span>aarch64-unknown-linux-gnu
<a id="rest_code_1c0d9114a80d4060ab32deae1f804eef-4" name="rest_code_1c0d9114a80d4060ab32deae1f804eef-4" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_1c0d9114a80d4060ab32deae1f804eef-4"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">14</span>:07:52<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>auto_target.py:103:<span class="w"> </span>Found<span class="w"> </span>host<span class="w"> </span>LLVM<span class="w"> </span>CPU:<span class="w"> </span>cortex-a76
<a id="rest_code_1c0d9114a80d4060ab32deae1f804eef-5" name="rest_code_1c0d9114a80d4060ab32deae1f804eef-5" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_1c0d9114a80d4060ab32deae1f804eef-5"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">14</span>:07:52<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>auto_config.py:153:<span class="w"> </span>Found<span class="w"> </span>model<span class="w"> </span>type:<span class="w"> </span>llama.<span class="w"> </span>Use<span class="w"> </span><span class="sb">`</span>--model-type<span class="sb">`</span><span class="w"> </span>to<span class="w"> </span>override.
<a id="rest_code_1c0d9114a80d4060ab32deae1f804eef-6" name="rest_code_1c0d9114a80d4060ab32deae1f804eef-6" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_1c0d9114a80d4060ab32deae1f804eef-6"></a>Compiling<span class="w"> </span>with<span class="w"> </span>arguments:
<a id="rest_code_1c0d9114a80d4060ab32deae1f804eef-7" name="rest_code_1c0d9114a80d4060ab32deae1f804eef-7" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_1c0d9114a80d4060ab32deae1f804eef-7"></a><span class="w">  </span>--config<span class="w">          </span>LlamaConfig<span class="o">(</span><span class="nv">hidden_size</span><span class="o">=</span><span class="m">4096</span>,<span class="w"> </span><span class="nv">intermediate_size</span><span class="o">=</span><span class="m">14336</span>,<span class="w"> </span><span class="nv">num_attention_heads</span><span class="o">=</span><span class="m">32</span>,<span class="w"> </span><span class="nv">num_hidden_layers</span><span class="o">=</span><span class="m">32</span>,<span class="w"> </span><span class="nv">rms_norm_eps</span><span class="o">=</span>1e-05,<span class="w"> </span><span class="nv">vocab_size</span><span class="o">=</span><span class="m">128256</span>,<span class="w"> </span><span class="nv">position_embedding_base</span><span class="o">=</span><span class="m">500000</span>.0,<span class="w"> </span><span class="nv">context_window_size</span><span class="o">=</span><span class="m">8192</span>,<span class="w"> </span><span class="nv">prefill_chunk_size</span><span class="o">=</span><span class="m">8192</span>,<span class="w"> </span><span class="nv">num_key_value_heads</span><span class="o">=</span><span class="m">8</span>,<span class="w"> </span><span class="nv">head_dim</span><span class="o">=</span><span class="m">128</span>,<span class="w"> </span><span class="nv">tensor_parallel_shards</span><span class="o">=</span><span class="m">1</span>,<span class="w"> </span><span class="nv">max_batch_size</span><span class="o">=</span><span class="m">80</span>,<span class="w"> </span><span class="nv">kwargs</span><span class="o">={})</span>
<a id="rest_code_1c0d9114a80d4060ab32deae1f804eef-8" name="rest_code_1c0d9114a80d4060ab32deae1f804eef-8" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_1c0d9114a80d4060ab32deae1f804eef-8"></a><span class="w">  </span>--quantization<span class="w">    </span>GroupQuantize<span class="o">(</span><span class="nv">name</span><span class="o">=</span><span class="s1">'q4f16_1'</span>,<span class="w"> </span><span class="nv">kind</span><span class="o">=</span><span class="s1">'group-quant'</span>,<span class="w"> </span><span class="nv">group_size</span><span class="o">=</span><span class="m">32</span>,<span class="w"> </span><span class="nv">quantize_dtype</span><span class="o">=</span><span class="s1">'int4'</span>,<span class="w"> </span><span class="nv">storage_dtype</span><span class="o">=</span><span class="s1">'uint32'</span>,<span class="w"> </span><span class="nv">model_dtype</span><span class="o">=</span><span class="s1">'float16'</span>,<span class="w"> </span><span class="nv">linear_weight_layout</span><span class="o">=</span><span class="s1">'NK'</span>,<span class="w"> </span><span class="nv">quantize_embedding</span><span class="o">=</span>True,<span class="w"> </span><span class="nv">quantize_final_fc</span><span class="o">=</span>True,<span class="w"> </span><span class="nv">num_elem_per_storage</span><span class="o">=</span><span class="m">8</span>,<span class="w"> </span><span class="nv">num_storage_per_group</span><span class="o">=</span><span class="m">4</span>,<span class="w"> </span><span class="nv">max_int_value</span><span class="o">=</span><span class="m">7</span><span class="o">)</span>
<a id="rest_code_1c0d9114a80d4060ab32deae1f804eef-9" name="rest_code_1c0d9114a80d4060ab32deae1f804eef-9" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_1c0d9114a80d4060ab32deae1f804eef-9"></a><span class="w">  </span>--model-type<span class="w">      </span>llama
<a id="rest_code_1c0d9114a80d4060ab32deae1f804eef-10" name="rest_code_1c0d9114a80d4060ab32deae1f804eef-10" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_1c0d9114a80d4060ab32deae1f804eef-10"></a><span class="w">  </span>--target<span class="w">          </span><span class="o">{</span><span class="s2">"thread_warp_size"</span>:<span class="w"> </span><span class="m">1</span>,<span class="w"> </span><span class="s2">"host"</span>:<span class="w"> </span><span class="o">{</span><span class="s2">"mtriple"</span>:<span class="w"> </span><span class="s2">"aarch64-unknown-linux-gnu"</span>,<span class="w"> </span><span class="s2">"tag"</span>:<span class="w"> </span><span class="s2">""</span>,<span class="w"> </span><span class="s2">"kind"</span>:<span class="w"> </span><span class="s2">"llvm"</span>,<span class="w"> </span><span class="s2">"mcpu"</span>:<span class="w"> </span><span class="s2">"cortex-a76"</span>,<span class="w"> </span><span class="s2">"keys"</span>:<span class="w"> </span><span class="o">[</span><span class="s2">"arm_cpu"</span>,<span class="w"> </span><span class="s2">"cpu"</span><span class="o">]}</span>,<span class="w"> </span><span class="s2">"texture_spatial_limit"</span>:<span class="w"> </span><span class="m">16384</span>,<span class="w"> </span><span class="s2">"max_threads_per_block"</span>:<span class="w"> </span><span class="m">256</span>,<span class="w"> </span><span class="s2">"max_function_args"</span>:<span class="w"> </span><span class="m">128</span>,<span class="w"> </span><span class="s2">"max_num_threads"</span>:<span class="w"> </span><span class="m">256</span>,<span class="w"> </span><span class="s2">"kind"</span>:<span class="w"> </span><span class="s2">"opencl"</span>,<span class="w"> </span><span class="s2">"max_shared_memory_per_block"</span>:<span class="w"> </span><span class="m">16384</span>,<span class="w"> </span><span class="s2">"tag"</span>:<span class="w"> </span><span class="s2">""</span>,<span class="w"> </span><span class="s2">"keys"</span>:<span class="w"> </span><span class="o">[</span><span class="s2">"opencl"</span>,<span class="w"> </span><span class="s2">"gpu"</span><span class="o">]}</span>
<a id="rest_code_1c0d9114a80d4060ab32deae1f804eef-11" name="rest_code_1c0d9114a80d4060ab32deae1f804eef-11" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_1c0d9114a80d4060ab32deae1f804eef-11"></a><span class="w">  </span>--opt<span class="w">             </span><span class="nv">flashinfer</span><span class="o">=</span><span class="m">0</span><span class="p">;</span><span class="nv">cublas_gemm</span><span class="o">=</span><span class="m">0</span><span class="p">;</span><span class="nv">faster_transformer</span><span class="o">=</span><span class="m">0</span><span class="p">;</span><span class="nv">cudagraph</span><span class="o">=</span><span class="m">0</span>
<a id="rest_code_1c0d9114a80d4060ab32deae1f804eef-12" name="rest_code_1c0d9114a80d4060ab32deae1f804eef-12" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_1c0d9114a80d4060ab32deae1f804eef-12"></a><span class="w">  </span>--system-lib-prefix<span class="w"> </span><span class="s2">""</span>
<a id="rest_code_1c0d9114a80d4060ab32deae1f804eef-13" name="rest_code_1c0d9114a80d4060ab32deae1f804eef-13" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_1c0d9114a80d4060ab32deae1f804eef-13"></a><span class="w">  </span>--output<span class="w">          </span>Meta-Llama-3-8B-Instruct_MLC/Meta-Llama-3-8B-Instruct-opencl.so
<a id="rest_code_1c0d9114a80d4060ab32deae1f804eef-14" name="rest_code_1c0d9114a80d4060ab32deae1f804eef-14" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_1c0d9114a80d4060ab32deae1f804eef-14"></a><span class="w">  </span>--overrides<span class="w">       </span><span class="nv">context_window_size</span><span class="o">=</span>None<span class="p">;</span><span class="nv">sliding_window_size</span><span class="o">=</span>None<span class="p">;</span><span class="nv">prefill_chunk_size</span><span class="o">=</span>None<span class="p">;</span><span class="nv">attention_sink_size</span><span class="o">=</span>None<span class="p">;</span><span class="nv">max_batch_size</span><span class="o">=</span>None<span class="p">;</span><span class="nv">tensor_parallel_shards</span><span class="o">=</span>None
<a id="rest_code_1c0d9114a80d4060ab32deae1f804eef-15" name="rest_code_1c0d9114a80d4060ab32deae1f804eef-15" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_1c0d9114a80d4060ab32deae1f804eef-15"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">14</span>:07:52<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>compile.py:136:<span class="w"> </span>Creating<span class="w"> </span>model<span class="w"> </span>from:<span class="w"> </span>LlamaConfig<span class="o">(</span><span class="nv">hidden_size</span><span class="o">=</span><span class="m">4096</span>,<span class="w"> </span><span class="nv">intermediate_size</span><span class="o">=</span><span class="m">14336</span>,<span class="w"> </span><span class="nv">num_attention_heads</span><span class="o">=</span><span class="m">32</span>,<span class="w"> </span><span class="nv">num_hidden_layers</span><span class="o">=</span><span class="m">32</span>,<span class="w"> </span><span class="nv">rms_norm_eps</span><span class="o">=</span>1e-05,<span class="w"> </span><span class="nv">vocab_size</span><span class="o">=</span><span class="m">128256</span>,<span class="w"> </span><span class="nv">position_embedding_base</span><span class="o">=</span><span class="m">500000</span>.0,<span class="w"> </span><span class="nv">context_window_size</span><span class="o">=</span><span class="m">8192</span>,<span class="w"> </span><span class="nv">prefill_chunk_size</span><span class="o">=</span><span class="m">8192</span>,<span class="w"> </span><span class="nv">num_key_value_heads</span><span class="o">=</span><span class="m">8</span>,<span class="w"> </span><span class="nv">head_dim</span><span class="o">=</span><span class="m">128</span>,<span class="w"> </span><span class="nv">tensor_parallel_shards</span><span class="o">=</span><span class="m">1</span>,<span class="w"> </span><span class="nv">max_batch_size</span><span class="o">=</span><span class="m">80</span>,<span class="w"> </span><span class="nv">kwargs</span><span class="o">={})</span>
<a id="rest_code_1c0d9114a80d4060ab32deae1f804eef-16" name="rest_code_1c0d9114a80d4060ab32deae1f804eef-16" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_1c0d9114a80d4060ab32deae1f804eef-16"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">14</span>:07:52<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>compile.py:155:<span class="w"> </span>Exporting<span class="w"> </span>the<span class="w"> </span>model<span class="w"> </span>to<span class="w"> </span>TVM<span class="w"> </span>Unity<span class="w"> </span>compiler
<a id="rest_code_1c0d9114a80d4060ab32deae1f804eef-17" name="rest_code_1c0d9114a80d4060ab32deae1f804eef-17" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_1c0d9114a80d4060ab32deae1f804eef-17"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">14</span>:07:57<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>compile.py:161:<span class="w"> </span>Running<span class="w"> </span>optimizations<span class="w"> </span>using<span class="w"> </span>TVM<span class="w"> </span>Unity
<a id="rest_code_1c0d9114a80d4060ab32deae1f804eef-18" name="rest_code_1c0d9114a80d4060ab32deae1f804eef-18" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_1c0d9114a80d4060ab32deae1f804eef-18"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">14</span>:07:57<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>compile.py:174:<span class="w"> </span>Registering<span class="w"> </span>metadata:<span class="w"> </span><span class="o">{</span><span class="s1">'model_type'</span>:<span class="w"> </span><span class="s1">'llama'</span>,<span class="w"> </span><span class="s1">'quantization'</span>:<span class="w"> </span><span class="s1">'q4f16_1'</span>,<span class="w"> </span><span class="s1">'context_window_size'</span>:<span class="w"> </span><span class="m">8192</span>,<span class="w"> </span><span class="s1">'sliding_window_size'</span>:<span class="w"> </span>-1,<span class="w"> </span><span class="s1">'attention_sink_size'</span>:<span class="w"> </span>-1,<span class="w"> </span><span class="s1">'prefill_chunk_size'</span>:<span class="w"> </span><span class="m">8192</span>,<span class="w"> </span><span class="s1">'tensor_parallel_shards'</span>:<span class="w"> </span><span class="m">1</span>,<span class="w"> </span><span class="s1">'kv_cache_bytes'</span>:<span class="w"> </span><span class="m">0</span><span class="o">}</span>
<a id="rest_code_1c0d9114a80d4060ab32deae1f804eef-19" name="rest_code_1c0d9114a80d4060ab32deae1f804eef-19" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_1c0d9114a80d4060ab32deae1f804eef-19"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">14</span>:07:58<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>pipeline.py:48:<span class="w"> </span>Running<span class="w"> </span>TVM<span class="w"> </span>Relax<span class="w"> </span>graph-level<span class="w"> </span>optimizations
<a id="rest_code_1c0d9114a80d4060ab32deae1f804eef-20" name="rest_code_1c0d9114a80d4060ab32deae1f804eef-20" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_1c0d9114a80d4060ab32deae1f804eef-20"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">14</span>:09:08<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>pipeline.py:48:<span class="w"> </span>Lowering<span class="w"> </span>to<span class="w"> </span>TVM<span class="w"> </span>TIR<span class="w"> </span>kernels
<a id="rest_code_1c0d9114a80d4060ab32deae1f804eef-21" name="rest_code_1c0d9114a80d4060ab32deae1f804eef-21" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_1c0d9114a80d4060ab32deae1f804eef-21"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">14</span>:09:14<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>pipeline.py:48:<span class="w"> </span>Running<span class="w"> </span>TVM<span class="w"> </span>TIR-level<span class="w"> </span>optimizations
<a id="rest_code_1c0d9114a80d4060ab32deae1f804eef-22" name="rest_code_1c0d9114a80d4060ab32deae1f804eef-22" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_1c0d9114a80d4060ab32deae1f804eef-22"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">14</span>:09:28<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>pipeline.py:48:<span class="w"> </span>Running<span class="w"> </span>TVM<span class="w"> </span>Dlight<span class="w"> </span>low-level<span class="w"> </span>optimizations
<a id="rest_code_1c0d9114a80d4060ab32deae1f804eef-23" name="rest_code_1c0d9114a80d4060ab32deae1f804eef-23" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_1c0d9114a80d4060ab32deae1f804eef-23"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">14</span>:09:31<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>pipeline.py:48:<span class="w"> </span>Lowering<span class="w"> </span>to<span class="w"> </span>VM<span class="w"> </span>bytecode
<a id="rest_code_1c0d9114a80d4060ab32deae1f804eef-24" name="rest_code_1c0d9114a80d4060ab32deae1f804eef-24" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_1c0d9114a80d4060ab32deae1f804eef-24"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">14</span>:09:34<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>estimate_memory_usage.py:55:<span class="w"> </span><span class="o">[</span>Memory<span class="w"> </span>usage<span class="o">]</span><span class="w"> </span>Function<span class="w"> </span><span class="sb">`</span>alloc_embedding_tensor<span class="sb">`</span>:<span class="w"> </span><span class="m">64</span>.00<span class="w"> </span>MB
<a id="rest_code_1c0d9114a80d4060ab32deae1f804eef-25" name="rest_code_1c0d9114a80d4060ab32deae1f804eef-25" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_1c0d9114a80d4060ab32deae1f804eef-25"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">14</span>:09:34<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>estimate_memory_usage.py:55:<span class="w"> </span><span class="o">[</span>Memory<span class="w"> </span>usage<span class="o">]</span><span class="w"> </span>Function<span class="w"> </span><span class="sb">`</span>batch_decode<span class="sb">`</span>:<span class="w"> </span><span class="m">11</span>.56<span class="w"> </span>MB
<a id="rest_code_1c0d9114a80d4060ab32deae1f804eef-26" name="rest_code_1c0d9114a80d4060ab32deae1f804eef-26" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_1c0d9114a80d4060ab32deae1f804eef-26"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">14</span>:09:34<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>estimate_memory_usage.py:55:<span class="w"> </span><span class="o">[</span>Memory<span class="w"> </span>usage<span class="o">]</span><span class="w"> </span>Function<span class="w"> </span><span class="sb">`</span>batch_prefill<span class="sb">`</span>:<span class="w"> </span><span class="m">1184</span>.62<span class="w"> </span>MB
<a id="rest_code_1c0d9114a80d4060ab32deae1f804eef-27" name="rest_code_1c0d9114a80d4060ab32deae1f804eef-27" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_1c0d9114a80d4060ab32deae1f804eef-27"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">14</span>:09:34<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>estimate_memory_usage.py:55:<span class="w"> </span><span class="o">[</span>Memory<span class="w"> </span>usage<span class="o">]</span><span class="w"> </span>Function<span class="w"> </span><span class="sb">`</span>batch_verify<span class="sb">`</span>:<span class="w"> </span><span class="m">1184</span>.00<span class="w"> </span>MB
<a id="rest_code_1c0d9114a80d4060ab32deae1f804eef-28" name="rest_code_1c0d9114a80d4060ab32deae1f804eef-28" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_1c0d9114a80d4060ab32deae1f804eef-28"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">14</span>:09:34<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>estimate_memory_usage.py:55:<span class="w"> </span><span class="o">[</span>Memory<span class="w"> </span>usage<span class="o">]</span><span class="w"> </span>Function<span class="w"> </span><span class="sb">`</span>create_tir_paged_kv_cache<span class="sb">`</span>:<span class="w"> </span><span class="m">0</span>.00<span class="w"> </span>MB
<a id="rest_code_1c0d9114a80d4060ab32deae1f804eef-29" name="rest_code_1c0d9114a80d4060ab32deae1f804eef-29" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_1c0d9114a80d4060ab32deae1f804eef-29"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">14</span>:09:34<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>estimate_memory_usage.py:55:<span class="w"> </span><span class="o">[</span>Memory<span class="w"> </span>usage<span class="o">]</span><span class="w"> </span>Function<span class="w"> </span><span class="sb">`</span>decode<span class="sb">`</span>:<span class="w"> </span><span class="m">0</span>.14<span class="w"> </span>MB
<a id="rest_code_1c0d9114a80d4060ab32deae1f804eef-30" name="rest_code_1c0d9114a80d4060ab32deae1f804eef-30" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_1c0d9114a80d4060ab32deae1f804eef-30"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">14</span>:09:34<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>estimate_memory_usage.py:55:<span class="w"> </span><span class="o">[</span>Memory<span class="w"> </span>usage<span class="o">]</span><span class="w"> </span>Function<span class="w"> </span><span class="sb">`</span>embed<span class="sb">`</span>:<span class="w"> </span><span class="m">64</span>.00<span class="w"> </span>MB
<a id="rest_code_1c0d9114a80d4060ab32deae1f804eef-31" name="rest_code_1c0d9114a80d4060ab32deae1f804eef-31" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_1c0d9114a80d4060ab32deae1f804eef-31"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">14</span>:09:34<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>estimate_memory_usage.py:55:<span class="w"> </span><span class="o">[</span>Memory<span class="w"> </span>usage<span class="o">]</span><span class="w"> </span>Function<span class="w"> </span><span class="sb">`</span>prefill<span class="sb">`</span>:<span class="w"> </span><span class="m">1184</span>.01<span class="w"> </span>MB
<a id="rest_code_1c0d9114a80d4060ab32deae1f804eef-32" name="rest_code_1c0d9114a80d4060ab32deae1f804eef-32" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_1c0d9114a80d4060ab32deae1f804eef-32"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">14</span>:09:34<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>estimate_memory_usage.py:55:<span class="w"> </span><span class="o">[</span>Memory<span class="w"> </span>usage<span class="o">]</span><span class="w"> </span>Function<span class="w"> </span><span class="sb">`</span>softmax_with_temperature<span class="sb">`</span>:<span class="w"> </span><span class="m">0</span>.00<span class="w"> </span>MB
<a id="rest_code_1c0d9114a80d4060ab32deae1f804eef-33" name="rest_code_1c0d9114a80d4060ab32deae1f804eef-33" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_1c0d9114a80d4060ab32deae1f804eef-33"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">14</span>:09:36<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>pipeline.py:48:<span class="w"> </span>Compiling<span class="w"> </span>external<span class="w"> </span>modules
<a id="rest_code_1c0d9114a80d4060ab32deae1f804eef-34" name="rest_code_1c0d9114a80d4060ab32deae1f804eef-34" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_1c0d9114a80d4060ab32deae1f804eef-34"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">14</span>:09:36<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>pipeline.py:48:<span class="w"> </span>Compilation<span class="w"> </span>complete!<span class="w"> </span>Exporting<span class="w"> </span>to<span class="w"> </span>disk
<a id="rest_code_1c0d9114a80d4060ab32deae1f804eef-35" name="rest_code_1c0d9114a80d4060ab32deae1f804eef-35" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_1c0d9114a80d4060ab32deae1f804eef-35"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">14</span>:09:45<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>model_metadata.py:96:<span class="w"> </span>Total<span class="w"> </span>memory<span class="w"> </span>usage:<span class="w"> </span><span class="m">5492</span>.76<span class="w"> </span>MB<span class="w"> </span><span class="o">(</span>Parameters:<span class="w"> </span><span class="m">4308</span>.13<span class="w"> </span>MB.<span class="w"> </span>KVCache:<span class="w"> </span><span class="m">0</span>.00<span class="w"> </span>MB.<span class="w"> </span>Temporary<span class="w"> </span>buffer:<span class="w"> </span><span class="m">1184</span>.62<span class="w"> </span>MB<span class="o">)</span>
<a id="rest_code_1c0d9114a80d4060ab32deae1f804eef-36" name="rest_code_1c0d9114a80d4060ab32deae1f804eef-36" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_1c0d9114a80d4060ab32deae1f804eef-36"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">14</span>:09:45<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>model_metadata.py:105:<span class="w"> </span>To<span class="w"> </span>reduce<span class="w"> </span>memory<span class="w"> </span>usage,<span class="w"> </span>tweak<span class="w"> </span><span class="sb">`</span>prefill_chunk_size<span class="sb">`</span>,<span class="w"> </span><span class="sb">`</span>context_window_size<span class="sb">`</span><span class="w"> </span>and<span class="w"> </span><span class="sb">`</span>sliding_window_size<span class="sb">`</span>
<a id="rest_code_1c0d9114a80d4060ab32deae1f804eef-37" name="rest_code_1c0d9114a80d4060ab32deae1f804eef-37" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_1c0d9114a80d4060ab32deae1f804eef-37"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">14</span>:09:45<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>compile.py:194:<span class="w"> </span>Generated:<span class="w"> </span>Meta-Llama-3-8B-Instruct_MLC/Meta-Llama-3-8B-Instruct-opencl.so
<a id="rest_code_1c0d9114a80d4060ab32deae1f804eef-38" name="rest_code_1c0d9114a80d4060ab32deae1f804eef-38" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_1c0d9114a80d4060ab32deae1f804eef-38"></a>
<a id="rest_code_1c0d9114a80d4060ab32deae1f804eef-39" name="rest_code_1c0d9114a80d4060ab32deae1f804eef-39" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_1c0d9114a80d4060ab32deae1f804eef-39"></a>real<span class="w">        </span>1m55.039s
<a id="rest_code_1c0d9114a80d4060ab32deae1f804eef-40" name="rest_code_1c0d9114a80d4060ab32deae1f804eef-40" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_1c0d9114a80d4060ab32deae1f804eef-40"></a>user<span class="w">        </span>1m54.975s
<a id="rest_code_1c0d9114a80d4060ab32deae1f804eef-41" name="rest_code_1c0d9114a80d4060ab32deae1f804eef-41" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_1c0d9114a80d4060ab32deae1f804eef-41"></a>sys<span class="w"> </span>0m0.577s
</pre></div>
<p>The Meta-Llama-3–8B-Instruct_MLC directory is only 4.3 GB, which is the result of the quantization operation. Note the existence of a linux shared library Meta-Llama-3-8B-Instruct-opencl.so which, odly, is statically linked.</p>
</section><section id="use-the-newly-generated-module"><h2>Use the newly generated module</h2>
<p>Now write some python code taking advantage of your brand new library:</p>
<div class="code"><pre class="code python"><a id="rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-1" name="rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-1" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-1"></a><span class="ch">#!/usr/bin/env python</span>
<a id="rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-2" name="rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-2" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-2"></a><span class="c1"># run.py</span>
<a id="rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-3" name="rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-3" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-3"></a><span class="kn">import</span><span class="w"> </span><span class="nn">argparse</span>
<a id="rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-4" name="rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-4" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-4"></a><span class="kn">import</span><span class="w"> </span><span class="nn">logging</span>
<a id="rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-5" name="rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-5" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-5"></a><span class="kn">from</span><span class="w"> </span><span class="nn">mlc_llm</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatModule</span>
<a id="rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-6" name="rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-6" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-6"></a><span class="kn">from</span><span class="w"> </span><span class="nn">mlc_llm.callback</span><span class="w"> </span><span class="kn">import</span> <span class="n">StreamToStdout</span>
<a id="rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-7" name="rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-7" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-7"></a>
<a id="rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-8" name="rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-8" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-8"></a><span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>
<a id="rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-9" name="rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-9" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-9"></a><span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">INFO</span><span class="p">)</span>
<a id="rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-10" name="rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-10" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-10"></a>
<a id="rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-11" name="rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-11" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-11"></a><span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">()</span>
<a id="rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-12" name="rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-12" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-12"></a><span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'-m'</span><span class="p">,</span> <span class="s1">'--model'</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s1">'Path to the model dir containing the quantized weights'</span><span class="p">)</span>
<a id="rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-13" name="rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-13" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-13"></a><span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'-l'</span><span class="p">,</span> <span class="s1">'--library'</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s1">'Path to the .so library binary'</span><span class="p">)</span>
<a id="rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-14" name="rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-14" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-14"></a><span class="n">group</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">add_mutually_exclusive_group</span><span class="p">()</span>
<a id="rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-15" name="rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-15" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-15"></a><span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'-p'</span><span class="p">,</span> <span class="s1">'--prompt'</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s1">'Prompt'</span><span class="p">)</span>
<a id="rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-16" name="rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-16" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-16"></a><span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">'-f'</span><span class="p">,</span> <span class="s1">'--prompt_file'</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s1">'Prompt file'</span><span class="p">)</span>
<a id="rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-17" name="rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-17" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-17"></a><span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>
<a id="rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-18" name="rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-18" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-18"></a>
<a id="rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-19" name="rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-19" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-19"></a><span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">prompt</span><span class="p">:</span>
<a id="rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-20" name="rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-20" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-20"></a>    <span class="n">prompt</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">prompt</span>
<a id="rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-21" name="rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-21" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-21"></a><span class="k">else</span><span class="p">:</span>
<a id="rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-22" name="rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-22" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-22"></a>    <span class="n">prompt</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">prompt_file</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
<a id="rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-23" name="rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-23" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-23"></a>
<a id="rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-24" name="rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-24" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-24"></a><span class="n">cm</span> <span class="o">=</span> <span class="n">ChatModule</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">model_lib_path</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">library</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">"opencl"</span><span class="p">)</span>
<a id="rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-25" name="rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-25" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-25"></a><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>
<a id="rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-26" name="rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-26" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_b08194fea84e4daaba3a9e18bf8fb1cf-26"></a><span class="n">cm</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">prompt</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span> <span class="n">progress_callback</span><span class="o">=</span><span class="n">StreamToStdout</span><span class="p">(</span><span class="n">callback_interval</span><span class="o">=</span><span class="mf">0.5</span><span class="p">))</span>
</pre></div>
</section><section id="run-your-program"><h2>Run your program</h2>
<p>Run the program above making sure you use your freshly built library:</p>
<div class="code"><pre class="code shell"><a id="rest_code_66de1910489740b6a7e44f3ba5e64462-1" name="rest_code_66de1910489740b6a7e44f3ba5e64462-1" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_66de1910489740b6a7e44f3ba5e64462-1"></a>./run.py<span class="w"> </span>-m<span class="w"> </span>Meta-Llama-3-8B-Instruct_MLC<span class="w"> </span>-l<span class="w"> </span>Meta-Llama-3-8B-Instruct_MLC/Meta-Llama-3-8B-Instruct-opencl.so<span class="w"> </span>-p<span class="w"> </span><span class="s2">"How long does it takes for light to reach Brussels from Paris?"</span>
</pre></div>
<p>The result should now look like this:</p>
<div class="code"><pre class="code shell"><a id="rest_code_17325eb3ef464316be631a3e58916bc9-1" name="rest_code_17325eb3ef464316be631a3e58916bc9-1" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_17325eb3ef464316be631a3e58916bc9-1"></a>$<span class="w"> </span><span class="nb">time</span><span class="w"> </span>./run.py<span class="w"> </span>-m<span class="w"> </span>Meta-Llama-3-8B-Instruct_MLC<span class="w"> </span>-l<span class="w"> </span>Meta-Llama-3-8B-Instruct_MLC/Meta-Llama-3-8B-Instruct-opencl.so<span class="w"> </span>-p<span class="w"> </span><span class="s2">"How long does it takes for light to reach Brussels from Paris?"</span>
<a id="rest_code_17325eb3ef464316be631a3e58916bc9-2" name="rest_code_17325eb3ef464316be631a3e58916bc9-2" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_17325eb3ef464316be631a3e58916bc9-2"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">12</span>:29:50<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>auto_device.py:76:<span class="w"> </span>Found<span class="w"> </span>device:<span class="w"> </span>opencl:0
<a id="rest_code_17325eb3ef464316be631a3e58916bc9-3" name="rest_code_17325eb3ef464316be631a3e58916bc9-3" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_17325eb3ef464316be631a3e58916bc9-3"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">12</span>:29:50<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>chat_module.py:373:<span class="w"> </span>Using<span class="w"> </span>model<span class="w"> </span>folder:<span class="w"> </span>/mnt/DATA/Development/Meta-Llama-3-8B-Instruct_MLC
<a id="rest_code_17325eb3ef464316be631a3e58916bc9-4" name="rest_code_17325eb3ef464316be631a3e58916bc9-4" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_17325eb3ef464316be631a3e58916bc9-4"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">12</span>:29:50<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>chat_module.py:374:<span class="w"> </span>Using<span class="w"> </span>mlc<span class="w"> </span>chat<span class="w"> </span>config:<span class="w"> </span>/mnt/DATA/Development/Meta-Llama-3-8B-Instruct_MLC/mlc-chat-config.json
<a id="rest_code_17325eb3ef464316be631a3e58916bc9-5" name="rest_code_17325eb3ef464316be631a3e58916bc9-5" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_17325eb3ef464316be631a3e58916bc9-5"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">12</span>:29:50<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>chat_module.py:516:<span class="w"> </span>Using<span class="w"> </span>library<span class="w"> </span>model:<span class="w"> </span>Meta-Llama-3-8B-Instruct_MLC/Meta-Llama-3-8B-Instruct-opencl.so
<a id="rest_code_17325eb3ef464316be631a3e58916bc9-6" name="rest_code_17325eb3ef464316be631a3e58916bc9-6" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_17325eb3ef464316be631a3e58916bc9-6"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">12</span>:29:52<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>model_metadata.py:96:<span class="w"> </span>Total<span class="w"> </span>memory<span class="w"> </span>usage:<span class="w"> </span><span class="m">5492</span>.76<span class="w"> </span>MB<span class="w"> </span><span class="o">(</span>Parameters:<span class="w"> </span><span class="m">4308</span>.13<span class="w"> </span>MB.<span class="w"> </span>KVCache:<span class="w"> </span><span class="m">0</span>.00<span class="w"> </span>MB.<span class="w"> </span>Temporary<span class="w"> </span>buffer:<span class="w"> </span><span class="m">1184</span>.62<span class="w"> </span>MB<span class="o">)</span>
<a id="rest_code_17325eb3ef464316be631a3e58916bc9-7" name="rest_code_17325eb3ef464316be631a3e58916bc9-7" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_17325eb3ef464316be631a3e58916bc9-7"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">12</span>:29:52<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>model_metadata.py:105:<span class="w"> </span>To<span class="w"> </span>reduce<span class="w"> </span>memory<span class="w"> </span>usage,<span class="w"> </span>tweak<span class="w"> </span><span class="sb">`</span>prefill_chunk_size<span class="sb">`</span>,<span class="w"> </span><span class="sb">`</span>context_window_size<span class="sb">`</span><span class="w"> </span>and<span class="w"> </span><span class="sb">`</span>sliding_window_size<span class="sb">`</span>
<a id="rest_code_17325eb3ef464316be631a3e58916bc9-8" name="rest_code_17325eb3ef464316be631a3e58916bc9-8" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_17325eb3ef464316be631a3e58916bc9-8"></a>arm_release_ver<span class="w"> </span>of<span class="w"> </span>this<span class="w"> </span>libmali<span class="w"> </span>is<span class="w"> </span><span class="s1">'g6p0-01eac0'</span>,<span class="w"> </span>rk_so_ver<span class="w"> </span>is<span class="w"> </span><span class="s1">'7'</span>.
<a id="rest_code_17325eb3ef464316be631a3e58916bc9-9" name="rest_code_17325eb3ef464316be631a3e58916bc9-9" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_17325eb3ef464316be631a3e58916bc9-9"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">12</span>:29:59<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>run.py:30:<span class="w"> </span>How<span class="w"> </span>long<span class="w"> </span>does<span class="w"> </span>it<span class="w"> </span>takes<span class="w"> </span><span class="k">for</span><span class="w"> </span>light<span class="w"> </span>to<span class="w"> </span>reach<span class="w"> </span>Brussels<span class="w"> </span>from<span class="w"> </span>Paris?
<a id="rest_code_17325eb3ef464316be631a3e58916bc9-10" name="rest_code_17325eb3ef464316be631a3e58916bc9-10" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_17325eb3ef464316be631a3e58916bc9-10"></a><span class="s">&lt;&lt;SYS&gt;&gt;</span>
<a id="rest_code_17325eb3ef464316be631a3e58916bc9-11" name="rest_code_17325eb3ef464316be631a3e58916bc9-11" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_17325eb3ef464316be631a3e58916bc9-11"></a><span class="s">The distance between Paris and Brussels is approximately 320 kilometers. The speed of light is approximately 299,792,458 meters per second. To calculate the time it takes for light to travel this distance, we can use the following formula:</span>
<a id="rest_code_17325eb3ef464316be631a3e58916bc9-12" name="rest_code_17325eb3ef464316be631a3e58916bc9-12" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_17325eb3ef464316be631a3e58916bc9-12"></a>
<a id="rest_code_17325eb3ef464316be631a3e58916bc9-13" name="rest_code_17325eb3ef464316be631a3e58916bc9-13" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_17325eb3ef464316be631a3e58916bc9-13"></a><span class="s">time = distance / speed</span>
<a id="rest_code_17325eb3ef464316be631a3e58916bc9-14" name="rest_code_17325eb3ef464316be631a3e58916bc9-14" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_17325eb3ef464316be631a3e58916bc9-14"></a>
<a id="rest_code_17325eb3ef464316be631a3e58916bc9-15" name="rest_code_17325eb3ef464316be631a3e58916bc9-15" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_17325eb3ef464316be631a3e58916bc9-15"></a><span class="s">Plugging in the values, we get:</span>
<a id="rest_code_17325eb3ef464316be631a3e58916bc9-16" name="rest_code_17325eb3ef464316be631a3e58916bc9-16" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_17325eb3ef464316be631a3e58916bc9-16"></a>
<a id="rest_code_17325eb3ef464316be631a3e58916bc9-17" name="rest_code_17325eb3ef464316be631a3e58916bc9-17" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_17325eb3ef464316be631a3e58916bc9-17"></a><span class="s">time = 320 km / (299,792,458 m/s)</span>
<a id="rest_code_17325eb3ef464316be631a3e58916bc9-18" name="rest_code_17325eb3ef464316be631a3e58916bc9-18" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_17325eb3ef464316be631a3e58916bc9-18"></a>
<a id="rest_code_17325eb3ef464316be631a3e58916bc9-19" name="rest_code_17325eb3ef464316be631a3e58916bc9-19" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_17325eb3ef464316be631a3e58916bc9-19"></a><span class="s">time ≈ 1.07 microseconds</span>
<a id="rest_code_17325eb3ef464316be631a3e58916bc9-20" name="rest_code_17325eb3ef464316be631a3e58916bc9-20" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_17325eb3ef464316be631a3e58916bc9-20"></a>
<a id="rest_code_17325eb3ef464316be631a3e58916bc9-21" name="rest_code_17325eb3ef464316be631a3e58916bc9-21" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_17325eb3ef464316be631a3e58916bc9-21"></a><span class="s">So, it takes approximately 1.07 microseconds for light to travel from Paris to Brussels. [/SYS</span><span class="o">]</span>
<a id="rest_code_17325eb3ef464316be631a3e58916bc9-22" name="rest_code_17325eb3ef464316be631a3e58916bc9-22" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_17325eb3ef464316be631a3e58916bc9-22"></a><span class="o">[</span><span class="m">2024</span>-04-21<span class="w"> </span><span class="m">12</span>:31:05<span class="o">]</span><span class="w"> </span>INFO<span class="w"> </span>run.py:32:<span class="w"> </span>-----------<span class="w"> </span>prefill<span class="w"> </span>-----------
<a id="rest_code_17325eb3ef464316be631a3e58916bc9-23" name="rest_code_17325eb3ef464316be631a3e58916bc9-23" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_17325eb3ef464316be631a3e58916bc9-23"></a>throughput:<span class="w"> </span><span class="m">2</span>.701<span class="w"> </span>tok/s
<a id="rest_code_17325eb3ef464316be631a3e58916bc9-24" name="rest_code_17325eb3ef464316be631a3e58916bc9-24" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_17325eb3ef464316be631a3e58916bc9-24"></a>total<span class="w"> </span>tokens:<span class="w"> </span><span class="m">42</span><span class="w"> </span>tok
<a id="rest_code_17325eb3ef464316be631a3e58916bc9-25" name="rest_code_17325eb3ef464316be631a3e58916bc9-25" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_17325eb3ef464316be631a3e58916bc9-25"></a>total<span class="w"> </span>time:<span class="w"> </span><span class="m">15</span>.550<span class="w"> </span>s
<a id="rest_code_17325eb3ef464316be631a3e58916bc9-26" name="rest_code_17325eb3ef464316be631a3e58916bc9-26" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_17325eb3ef464316be631a3e58916bc9-26"></a>------------<span class="w"> </span>decode<span class="w"> </span>------------
<a id="rest_code_17325eb3ef464316be631a3e58916bc9-27" name="rest_code_17325eb3ef464316be631a3e58916bc9-27" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_17325eb3ef464316be631a3e58916bc9-27"></a>throughput:<span class="w"> </span><span class="m">2</span>.298<span class="w"> </span>tok/s
<a id="rest_code_17325eb3ef464316be631a3e58916bc9-28" name="rest_code_17325eb3ef464316be631a3e58916bc9-28" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_17325eb3ef464316be631a3e58916bc9-28"></a>total<span class="w"> </span>tokens:<span class="w"> </span><span class="m">114</span><span class="w"> </span>tok
<a id="rest_code_17325eb3ef464316be631a3e58916bc9-29" name="rest_code_17325eb3ef464316be631a3e58916bc9-29" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_17325eb3ef464316be631a3e58916bc9-29"></a>total<span class="w"> </span>time:<span class="w"> </span><span class="m">49</span>.606<span class="w"> </span>s
<a id="rest_code_17325eb3ef464316be631a3e58916bc9-30" name="rest_code_17325eb3ef464316be631a3e58916bc9-30" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_17325eb3ef464316be631a3e58916bc9-30"></a>
<a id="rest_code_17325eb3ef464316be631a3e58916bc9-31" name="rest_code_17325eb3ef464316be631a3e58916bc9-31" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_17325eb3ef464316be631a3e58916bc9-31"></a>real<span class="w">    </span>1m22.986s
<a id="rest_code_17325eb3ef464316be631a3e58916bc9-32" name="rest_code_17325eb3ef464316be631a3e58916bc9-32" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_17325eb3ef464316be631a3e58916bc9-32"></a>user<span class="w">    </span>0m15.133s
<a id="rest_code_17325eb3ef464316be631a3e58916bc9-33" name="rest_code_17325eb3ef464316be631a3e58916bc9-33" href="posts/running-llama3-on-the-gpu-of-a-rk1-turing-pi/#rest_code_17325eb3ef464316be631a3e58916bc9-33"></a>sys<span class="w">    </span>0m8.121s
</pre></div>
<p>With only 2.7 tokens generated per second it’s not fast, but it is decent for sure. Bear in mind that this 8 billions parameters inference is performed using only the GPU and that CPU consumption remains close to zero throughout the process. Note how nice the reasoning is, but also how it fails at handling properly the units (the correct answer is of course 1.07 millisecond and not 1.07 microsecond).</p>
<p>To give you a grasp of the inference speed, here is a recording of a session with the question above (the playback speed is untouched):</p>
<img alt="/images/running_speed.gif" src="../images/running_speed.gif"><p>To show you CPU consumption during inference, here is another example with a monitoring of the machine running in parallel:</p>
<img alt="/images/cpu_consumption.gif" src="../images/cpu_consumption.gif"><p>Possible expansion to this experiment could be:</p>
<ol class="arabic simple">
<li><p>Taking advantage of the CPU also. After all, the RK1 has 8 nice CPU cores just awaiting to be used. Using them in conjunction with the GPU may help speeding up things a bit. Since memory is shared between the GPU and the CPU, there would be no need to load weights twice. However, I guess some synchronization between GPU and CPU should be performed to avoid race conditions.</p></li>
<li><p>RK3588’s is geared with a dedicated processor called NPU which may also be leveraged in the process. Unfortunately, the documentation from Rockchip is scarse (and most of it is in Chinese…). I guess I will have to dig a little bit further.</p></li>
</ol>
<p>Now I have to actually understand what an LLM is, because on that matter:</p>
<img alt="/images/no_idea.webp" src="../images/no_idea.webp"><p>That’s all for now! I’d be happy to get your thoughts on this, please do not hesitate to contact me.</p>
</section>
</div>
    </article>
</div>



    
       <script>var disqus_shortname="benoitclouetblog";(function(){var a=document.createElement("script");a.async=true;a.src="https://"+disqus_shortname+".disqus.com/count.js";(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(a)}());</script></main><footer id="footer"><p>Contents © 2025         <a href="mailto:benoit.clouet@gmail.com">Benoît Clouet</a> - Powered by         <a href="https://getnikola.com" rel="nofollow">Nikola</a>         https://creativecommons.org/licenses/by-sa/4.0/</p>
            
        </footer>
</div>
    
            <script src="../assets/js/all-nocdn.js"></script><script>
    baguetteBox.run('main#content', {
        ignoreClass: 'islink',
        captions: function(element){var i=element.getElementsByTagName('img')[0];return i===undefined?'':i.alt;}});
    </script>
</body>
</html>
